---
title: "Session 3 Uncertainty visualizations"
author: "Xiaoying Pu, Lace Padilla"
date: "3/3/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(tidymodels)
library(modelr)
library(brms)
library(tidybayes)
library(ggdist)
library(distributional)
library(ordinal)
library(ggrepel)
library(glue)
library(dabestr)

theme_set(theme_tidybayes())
```

## Introduction

We will revisit Datasets 1 and 2 from last time, focusing on exploring the **visualizations** instead of the analysis. By the end of this tutorial, you will learn to:

1.  Apply the **Grammar of Graphics** to build simple plots
2.  Identify the types of **uncertainty** from model outputs and modify code to visualize outputs and uncertainty
3.  Use resources to find options for making a plot more **expressive** and evaluate its **usability**

### Pre-survey

What makes a plot? How do you systematically describe a plot, like linguists using **grammar** to describe a language?

Go to ==TODO== (survey link)

It's OK if you're sure about your answers! It's all part of the plan ðŸ¤”

\[Review survey response and adjust timing accordingly\]

------------------------------------------------------------------------

## Activity 1: exploring data

### Load the data

```{r}
(df1 <- read_csv("data/blinded.csv") %>%
  filter(experiment == 1) %>%
  mutate(
    condition = factor(condition), 
    participant_id = paste0("P", str_pad(row_number(), 2, pad = "0")))
)
```

### Explore the data with ggplot

We modeled how `condition` (graph or no graph) affected `effectiveness`, a Likert scale rating from 1 to 9.

To start out, create a scatterplot of bill length versus bill depth for the three species. Your plot should look like this:

![](images/000005.png)

This is the Grammar of Graphics specification:

-   Visual channel encoding

    -   x-axis \<- effectiveness
    -   y-axis \<- condition

-   Mark/geometry: point

```{r}
df1 %>%
  ggplot(aes(
    x = effectiveness, 
    y = condition)) +  # EXERCISE: add color
  geom_point() +       # EXERCISE: change to jitter
  scale_x_continuous(breaks = 1:9)
```

Alternative: try aggregation

```{r}
df1 %>%
  count(effectiveness, condition, name = "n") %>%
  pivot_wider(names_from = condition, values_from = n, values_fill = 0)
```

Visualize the aggregated dataset

```{r}
df1 %>%
  count(condition, effectiveness, name = "n") %>%
  ggplot(aes(x = effectiveness, y = n, color = condition)) + 
  geom_point() +     # EXERCISE: change to line chart (geom_line)
  # EXERCISE: point + line??
  scale_x_continuous(breaks = 1:9)
```



## Activity 2: t-test/simple linear regression


|                         | Frequentist | Bayesian |
|-------------------------|-------------|----------|
| Table summary           |             |          |
| Point estimate          |             |          |
| Interval-parameter      |             |          |
| Distribution-parameter  |             |          |
| Interval-prediction     |             |          |
| Distribution-prediction |             |          |




### Frequentist and Bayesian models

Baseline: table/textual reporting


t-test is equivalent to a linear model estimating two means. Using `lm` because the output is easier to wrangle (good explainer: <https://lindeloev.github.io/tests-as-linear/#61_one-way_anova_and_kruskal-wallis>)

```{r}
(m_t_test <- lm(effectiveness ~ - 1 + condition, data = df1))
```


```{r}
(m_t_test_bayesian <- readRDS("../02-bayesian_stats/rds/dataset1.brm.bayesiant.rds"))
```


### Build CI and PI dataframes; table views

For confidence interval (CI)

- `estimate` column is for the estimates of the group means
- `std.error` is the standard error
- 95% CI is $t_{1 - 0.05/2, df}$, calculated as `qt(1 - 0.05/2, df)`. 

We won't calculate CI intervals directly. Instead we use `distributional::dist_student_t` and `ggdist` functions.

```{r}
(means_t_freq <- m_t_test %>% 
   tidy() %>%
   mutate(condition = str_remove(term, "condition"), .before = 1) %>%
   select(-term)
)
```
For the Bayesian model, we get draws of all the parameters of the t-distribution (mu/.epred, sigma, nu). There is credible interval (CI) for Bayesian models, but we're not summarizing intervals yet

```{r }
(means_t_bayes <- data_grid(df1, condition) %>%
  add_epred_draws(m_t_test_bayesian, newdata = . ,dpar = TRUE))
```

Prediction interval (PI). `.fitted` is the same as the `estimate` above.

```{r}
# predict() returns $residual.scale
preds_t_freq_obj <- predict(m_t_test, newdata = data_grid(df1, condition), 
                     se.fit=TRUE, interval = "prediction", level = 0.95)

(preds_t_freq <- m_t_test %>%
  augment(newdata = data_grid(df1, condition), se_fit = TRUE) %>%
  mutate(
    .se.pred = sqrt(.se.fit ^ 2 + preds_t_freq_obj$residual.scale^2),
    df = preds_t_freq_obj$df
  ) 
)
```

```{r }
(preds_t_bayes <- data_grid(df1, condition) %>%
    add_predicted_draws(m_t_test_bayesian))
```

#### Point estimates of the mean

```{r }
means_t_freq %>%
  ggplot(aes(x = estimate, y = condition)) + 
  geom_point() +
  scale_x_continuous(breaks = 1:9, limits = c(1, 9)) + 
  NULL
```

```{r}
# EXERCISE
(p_pt_est <- means_t_bayes %>%
  median_qi(.epred, .width = c(0.95)) %>%
  ggplot(aes(x = .epred, y = condition)) + 
  geom_point(aes(color = "Bayesian")) + 
  geom_point(
    aes(x = estimate, 
    color = "Frequentist"), 
    data = means_t_freq, 
    position = position_nudge(y = -0.1)) + 
  scale_x_continuous("Effectiveness", breaks = 1:9, limits = c(1, 9)) + 
  scale_color_manual("Model", 
                     breaks = c("Bayesian", "Frequentist"), 
                     values  = c("#45829f", "#000000") ) +
  NULL
)

# REFLECTION: what just happened? How is that legend generated?
# layer_data(p_pt_est, i = 1)
```


#### Intervals - parameter and prediction

Add interval for uncertainty. In the frequentist world, the *confidence distribution* for the parameters follows the student-t distribution. <https://mjskay.github.io/ggdist/articles/freq-uncertainty-vis.html>

`distributional::dist_student_t` conveniently returns a student-t distribution, all we need are the three parameters we calculated earlier

- df: degree of freedom (N-2)
- mu: estimate/.fitted for the mean
- sigma: standard error

Note: `dist_student_t` only works with `xdist` aesthetic from the ggdist package.

```{r }
means_t_freq %>%
  ggplot(aes(
    xdist = dist_student_t( # EXERCISE: what does this mean?
      df = df.residual(m_t_test), 
      mu = estimate, 
      sigma = std.error), 
    y = condition)) + 
  stat_pointinterval() +
  scale_x_continuous("response", breaks = 1:9, limits = c(1, 9)) + 
  NULL
```

The prediction distribution also follows the t-distribution, so we only need to change the `sigma` parameter. Show that PI is wider than the CI in the plot below!

```{r}
preds_t_freq %>%
  ggplot(aes(y = condition)) + 
  stat_interval(aes(
    xdist = dist_student_t( # EXERCISE: what does this mean?
      df = df,
      mu = .fitted, 
      sigma = .se.pred) 
  )) + 
  # EXERCISE: put CI (dot and whisker) in this plot
  # stat_pointinterval(aes(
  #   xdist = dist_student_t( # EXERCISE: what does this mean?
  #     df = df,
  #     mu = .fitted,
  #     sigma = .se.fit)),
  #   position = position_nudge(y = -.2)) +
  # EXERCISE: put raw data in this plot
  # geom_jitter(aes(x = effectiveness), height = 0.1, data = df1) + 
  scale_x_continuous("effectiveness", breaks = 1:11, limits = c(1, 11)) + 
  scale_color_brewer() + 
  NULL
  
```

#### Distribution


EXERCISE: why are the densities so narrow? Does it make sense? What encoding do you prefer?

```{r }
means_t_freq %>%
  ggplot(aes(y = condition)) +
  # EXERCIESE: add raw data
  geom_jitter(
    aes(
      x = effectiveness,
      y = condition),
    data = df1, height = 0.05, alpha = .5) +
  stat_halfeye(             # EXERCIESE: change to stat_dots
    aes(xdist =dist_student_t(
      df = df.residual(m_t_test), 
      mu = estimate, 
      sigma = std.error)),
    scale = 0.5, fill = "#8c96c6",
    position = position_nudge(y = 0.1)) + 
  geom_label_repel(aes(.fitted, y = condition), data = aug_df1 %>% slice_tail(),
                   label = "Confidence distribution of the mean", box.padding = 1, 
                   position = position_nudge(y = 0.1), max.overlaps = Inf) + 
  # EXERCISE: add labels for the raw data
  geom_label_repel(
    aes(.fitted, y = condition),
    data = aug_df1 %>% slice_head(),
    label = "Jittered raw data", box.padding = 1,
    position = position_nudge_repel(y = -0.2)) +
  scale_x_continuous(breaks = 0:10, limits = c(0, 10)) + 
  NULL

```


```{r}
preds_t_freq %>%
  ggplot(aes(y = condition)) + 
  stat_slab(
    aes(xdist = dist_student_t(
      df = df, 
      mu = .fitted, 
      sigma = .se.pred)),
    slab_color="gray65", fill = NA, scale = 0.7) +
    geom_jitter(
    aes(
      x = effectiveness,
      y = condition),
    data = df1, height = 0.05, shape = 21, fill = "#9ECAE1",  size = 2) +
  scale_x_continuous(breaks = 1:9) +
  NULL
```


### Ordinal linear regression

<https://bookdown.org/ajkurz/Statistical_Rethinking_recoded/monsters-and-mixtures.html#ordered-categorical-outcomes>

We've seen this before

```{r}
df1 %>%
  count(condition, effectiveness, name = "n") %>%
  ggplot(aes(x = effectiveness, y = n, color = condition)) + 
  geom_point() + 
  geom_line() + 
  scale_x_continuous(breaks = 1:9) + 
  NULL
```

Building up to the ordinal linear regression model... introducing the cumulative proportions ("odds"), and cumulative log odds (computed with `logit()`)

```{r}
logit <- function(x) log(x / (1 - x))

(cumu_df1 <- df1 %>%
  count(condition, effectiveness, name = "n") %>%
  add_row(condition = "graph", effectiveness = 2, n = 0) %>%
  complete(condition, effectiveness, fill = list(n = 0)) %>%
  group_by(condition) %>%
  mutate(
    pr_k = n / sum(n),
    cum_pr_k = cumsum(pr_k),
    cum_pr_k_1 = cum_pr_k - (pr_k),
    logit_cum_pr_k = logit(cum_pr_k))
)
```

```{r}
cumu_df1 %>%
  filter(!is.infinite(logit_cum_pr_k)) %>%
  ggplot(aes(x = effectiveness, y = logit_cum_pr_k, color = condition, label = round(logit_cum_pr_k, 2))) + 
  geom_vline(xintercept = 6) + 
  geom_label_repel(data = cumu_df1 %>% filter(effectiveness == 6)) + 
  geom_point() + 
  geom_line() + 
  scale_x_continuous(breaks = 1:9) + 
  ylab("log-cumulative-odds")
```

Once we have the estimates in the cumulative log odds space, can do inverse logit (`brms::inv_logit_scaled()`), and get proportions out of the cumulative proportions.

```{r}
cumu_df1 %>%
  ggplot(aes(x = effectiveness, y = cum_pr_k)) + 
  geom_line() +
  geom_segment(aes(
    x = effectiveness, 
    xend = effectiveness,
    y = cum_pr_k, 
    yend = cum_pr_k_1),
    color = "grey") +
  geom_segment(aes(
    x = effectiveness - 1, 
    xend = effectiveness,
    y = cum_pr_k_1, 
    yend = cum_pr_k_1),
    linetype = "dotted", color = "grey") +
  geom_point() +
  scale_x_continuous(breaks = 1:9) + 
  facet_grid(~condition)
```

```{r}
(m_polr <- df1 %>% 
  mutate(effectiveness = ordered(effectiveness, levels = as.character(1:9))) %>% 
  MASS::polr(effectiveness ~ condition, data = ., Hess=TRUE) 
)
```

```{r}
tidy(m_polr)
```

```{r}
(condition_no_graph <- tidy(m_polr) %>% slice_head())
```

Showing estimates on the cumulative log odds scale

```{r}
tidy(m_polr) %>%
  dplyr::slice(-1) %>%
  crossing(condition = c("graph", "no_graph")) %>%
  mutate(estimate = 
           ifelse(condition == "no_graph", 
                  estimate + condition_no_graph$estimate, 
                  estimate)) %>%
  mutate(.upper = estimate + 1.96 * std.error, 
         .lower = estimate - 1.96 * std.error)  %>%
  mutate(condition = factor(ifelse(condition == "graph", 0, 1))) %>%
  ggplot(aes(x = condition, y = estimate, group = term)) + 
  facet_grid(~ term) + # EXERCISE: uncomment to see data better
  geom_lineribbon(aes(ymin = .lower, ymax = .upper, color = term), alpha = 0.4) + 
  scale_color_viridis_d() 

```


Going back to the data space... show predicted proportions and uncertainty

```{r}
# EXERCISE: how to show uncertainty with this?

as.data.frame(predict(m_olr_freq, type.predict = "prob", se.fit = TRUE)) %>%
  bind_cols(df1 %>% select(effectiveness, condition))  %>%
  group_by(effectiveness, condition) %>% 
  slice_head() %>%
  ungroup()   %>%
  ggplot(aes(x = effectiveness, y = fit, fill = condition)) + 
  geom_col(position = "dodge") + 
  # geom_pointinterval(   # EXERCISE: put in the interval 
  #   aes(ymin = fit - 1.96 * se.fit, ymax = fit + 1.96 * se.fit),
  #   position = "dodge") + 
  scale_x_continuous(breaks = 1:9) + 
  ylab("Proportion")
```

## Dataset 1, Bayesian land

### Dataset 1, Bayesian t-test

Load the model from last time....

```{r }
```

Get estimates for parameters and outcome predictions (1..9).



Visualize parameter uncertainty, predictive uncertainty, and raw data.

EXERCISE:

-   (which visual element?) \<- Parameter uncertainty
-   (which visual element?) \<- Predictive uncertainty
-   (which visual element?) \<- Raw data (with intrinsic uncertainty, too!)

```{r}
df1 %>%
  ggplot(aes(x = effectiveness, y = condition)) + 
  stat_interval(aes(x = .prediction), data = preds_df1_t) +
  
  # EXERCISE: change to density plot
  stat_pointinterval(aes(x = .epred), data = means_df1_t,
                     .width = c(.66, .95),
                     position = position_nudge(y = -0.2)) +
  geom_jitter(height = 0.1) +
  scale_x_continuous(breaks = 1:9)+
  scale_color_brewer()
```

An alternative way of seeing the uncertainty, in Kruschke style. The bunch of density lines shows both parameter and predictive uncertainty.

```{r}
means_df1_t %>%
  sample_draws(30) %>%
  ggplot(aes(y = condition)) + 
  stat_slab(
    aes(xdist = dist_student_t(nu, mu, sigma)),
    slab_color="gray65", alpha = 0.05, fill = NA, scale = 0.7) +
  geom_jitter(aes(x = effectiveness), data = df1, shape = 21, fill = "#9ECAE1",  size = 2, width = 0.1, height = 0.1) +
  scale_x_continuous(breaks = 1:9)
  NULL
```

### Dataset 1, Bayesian OLR

There're starter values and stuff, not bothered just yet <https://bookdown.org/ajkurz/Statistical_Rethinking_recoded/monsters-and-mixtures.html#ordered-categorical-outcomes>

```{r dat1-bayesian-model3}
(m_olr_bayes <- readRDS("../02-bayesian_stats/rds/dataset1.brm.olr1.rds"))
```

Get posterior estimates for the parameters and predictions (outcome on the scale of 1...9)

```{r}
(means_df1_olr <- expand(df1, condition) %>%
  add_epred_draws(m_olr_bayes, dpar = TRUE) %>%
   rename(effectiveness = .category)
)
```
```{r}
means_df1_olr %>%
  group_by(.draw) %>%
  filter(cur_group_id()== 1)
```

```{r}
(preds_df1_olr <- expand(df1, condition) %>%
    add_predicted_draws(m_olr_bayes) %>%
    select(-c(.chain, .iteration)) %>%
   drop_na()
 )

preds_df1_olr %>%
  ungroup() %>%
  expand(nesting(.draw))

```

EXERCISE: why does this look different from the frequentist version?

```{r}
(df1_prop <- df1 %>%
  count(condition, effectiveness) %>%
  group_by(condition) %>%
  mutate(prop = n/sum(n))
)

means_df1_olr %>%
  ggplot(aes(x = condition, y = .epred)) + 
  stat_lineribbon()  + 
  geom_point(aes(x = condition, y = prop), data = df1_prop) + 
  scale_fill_brewer() + 
  facet_grid(~ effectiveness) +
  theme(axis.text.x = element_blank()) + 
  xlab("Condition: graph - no graph") + 
  ylab("Proportion")
```

EXERCISE (challenge): follow <https://bookdown.org/ajkurz/Statistical_Rethinking_recoded/monsters-and-mixtures.html#ordered-categorical-outcomes> to construct a stacked version

```{r}
(means_df1_olr_compare <- means_df1_olr %>%
  group_by(effectiveness) %>%
  compare_levels(variable = .epred, by = condition ) 
)

(df1_prop_diff <- df1_prop %>%
  pivot_wider(id_col = effectiveness, names_from = condition, values_from = prop) %>%
  drop_na() %>%
  mutate(diff = no_graph - graph)
)

means_df1_olr_compare %>%
  ggplot(aes(x = effectiveness, y = .epred)) + 
  stat_interval(.width = c(0.95)) +  # EXERCISE: can you be more expressive with uncertainty?
  geom_hline(                        # EXERCISE: add reference line y = 0
    yintercept = 0, linetype = "dashed", color = "grey") + 
  geom_point(aes(y = diff), data= df1_prop_diff) +  #EXERCISE: add raw data
  scale_color_brewer() + 
  ylab("no graph - graph") + 
  labs(title = "Difference in proportions: no graph - graph") + 
  NULL
```

```{r}
preds_df1_olr %>%
  count(condition, .prediction) %>%
  ggplot(aes(.prediction, n, fill = condition)) +
  geom_col(position = "dodge")

```

## Packages Information

```{r}
sessionInfo()
```
