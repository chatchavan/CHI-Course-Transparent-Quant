---
title: "chi22-course"
author: "Abhraneel Sarma"
date: "3/3/2022"
output: 
  html_document:
    highlight: tango
---

<style>
.sourceCode.r{
  background-color:white
}
</style>


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(dplyr)
library(tibble)
library(purrr)
library(tidyr)
library(forcats)

library(broom)
library(broom.mixed)

library(modelr)

library(brms)
library(tidybayes)

library(ggdist)
library(ggplot2)
library(knitr)
theme_set(theme_ggdist() + 
            theme(strip.background = element_blank()))

IF_RUN_MODEL <- T
```


# Introduction

In this document, we will outline the Bayesian analogs of the statistical analyses described [here](https://github.com/chatchavan/CHI-Course-Transparent-Quant/blob/master/frequentist.Rmd) (and in the previous course lecture).


Helper functions.

```{r helper}

# this function extracts results from different models and generate results of the same format to be used in visualizations
tidy.wrapper = function(model) {
  if (class(model) == "lm") {
    tidy(model, conf.int = TRUE) %>%
      select(-c(statistic, p.value)) %>%
      mutate(model = "Frequentist") %>%
      select(model, everything())
  } else if (class(model) == "brmsfit") {
    tidy(model) %>%
      filter(effect == "fixed") %>%
      select(c(term:conf.high)) %>%
      mutate(model = "Bayesian") %>%
      select(model, everything())
  } else {
    stop("unknown model class")
  }
}
```

TODO: explain the dataset here


# Dataset 1

### Let's first load and look at the data in a table

```{r load-dataset}

# Fumemng -> Abhraneel I'm using the Rproj in the root folder, although my path is identical...

dataset = readr::read_csv("02-bayesian_stats/data/blinded.csv")
# dataset = readr::read_csv("~/Documents/Github/chi22-course/data/blinded.csv")

kable(head(dataset))

```  


```{r plot-dataset, fig.height = 3, fig.width = 7}
dataset %>% 
  mutate(effectiveness = fct_rev(factor(effectiveness, levels = 1:9))) %>%
  
  # stacked bar plot
  ggplot(aes(x = condition, fill = effectiveness)) +
  geom_bar(position = "stack", stat="count") +
  
  # plot data for different experiments as small multiples
  facet_wrap( ~ experiment) +
  
  # grey color scale is robust for colorblind
  scale_fill_brewer(palette="Greys", drop = FALSE) +
  
  # horizontal plot
  coord_flip() +
  
  # legend
  guides(fill = guide_legend(reverse = TRUE)) 
```

As we can see above, the original dataset contains results from four different experiments. For the purposes of this lecture, we will confine ourselves to the first experiment.

```{r filter-data}
exp1.data = dataset %>%
  filter(experiment == 1)

exp1.data
```


## Model 1. Wilcoxon signed rank test

This is a non-parametric test which we will skip for now. Although, there exists Bayesian non-parametric methods, they are more advanced for this lecture.

## Model 2. t-test

This is the linear model equivalent for the paired sample t-test

```{r dataset1-lm}
dataset1.lm.freqt <-
  lm(
    effectiveness ~ condition - 1, 
    data = exp1.data
  )
```


```{r dataset1-bayesian-t-test-formula}
dataset1.brm.bayesiant.formula <- bf(
    effectiveness ~ condition - 1,
    family = student()
  )
```


```{r dataset1-bayesian-t-test-get-prior}

kable(as.tibble(get_prior(dataset1.brm.bayesiant.formula, data = exp1.data)))

```

```{r dataset1-bayesian-t-test-run}
dataset1.brm.bayesiant.priors = c(
      prior(normal(0, 1), class = "b"), # there's a lot of data so even fairly "strong" priors are going to not matter so much here
      prior(student_t(3, 0, 1), class = "sigma")
      )

if(IF_RUN_MODEL){
  dataset1.brm.bayesiant = 
  brm(dataset1.brm.bayesiant.formula,
    prior = dataset1.brm.bayesiant.priors,
    data = exp1.data,
    seed = 99,
    backend = "cmdstanr", #Fumeng: I have to use this as my backend. 'rstan' backend doesn't work on my laptops...
    chains = 4, 
    cores = 4,
    file = "02-bayesian_stats/rds/dataset1.brm.bayesiant.rds"
  )

} else{
    dataset1.brm.bayesiant <- readRDS(file = "02-bayesian_stats/rds/dataset1.brm2.bayesiant.rds")
}


```

```{r}
 summary(dataset1.brm.bayesiant)
```

```{r dataset1-t-test-posterior}

posterior_samples <- tibble(condition = c('graph', 'no_graph')) %>%
  add_fitted_draws(dataset1.brm.bayesiant, re_formula = NA)

kable(head(posterior_samples))
```

```{r}
kable(posterior_samples %>%
  mean_qi())
```

```{r fig.height=4, fig.width=10}
posterior_samples %>%
  ggplot(aes(x = .value, fill = condition)) +
  geom_histogram(
    exp1.data,
    alpha = .5,
    fill = 'gray50',
    mapping = aes(x = effectiveness, y = (..count..) / sum(..count..))
  ) +
  geom_histogram(color = NA, aes(y = (..count..) / sum(..count..)), binwidth = .1) +
  facet_wrap(condition ~ .) +
  scale_color_brewer(palette = "Set1") +
  scale_fill_brewer(palette = "Set1") +
  scale_x_continuous(breaks = 1:9) +
  xlab('effectiveness') + ylab('frequency')

```
Next, we visualise the results, along with a side-by-side comparison of the frequentist estimates:

```{r dataset1-t-test-compare, fig.height=4, fig.width=10, warning=FALSE}

bind_rows(tidy.wrapper(dataset1.lm.freqt),
          tidy.wrapper(dataset1.brm.bayesiant)) %>%
  ggplot() +
  geom_pointrange(
    aes(
      x = model,
      y = estimate,
      ymin = conf.low,
      ymax = conf.high,
      color = term
    ),
    position = position_dodge(width = 0.2)
  ) +
  scale_color_brewer(palette = "Set1") +
  ylab('effectiveness') +
  scale_y_continuous(breaks = 1:9, limits = c(1, 9)) +
  coord_flip()
```



## Model 3. Ordinal Logistic Regression


```{r ordinal-logistic-regression}

test <- brm(effectiveness ~ condition, 
    data = exp1.data, 
    family=cumulative("logit"), 
    warmup = 2500,
    iter = 3500,
    backend = 'cmdstanr'
    )

# TODO priors

summary(test)

```

```{r}
#TODO

posterior_samples <- tibble(condition = c('graph', 'no_graph')) %>%
     add_fitted_draws(test, re_formula = NA) 


posterior_samples
```
```{r}

posterior_samples %>% 
  ggplot(., aes(x = .value)) +
  geom_histogram() +
  facet_grid(.~condition)

```
# Dataset 2


Load the data

```{r load-dataset-2}
dataset2 = readr::read_csv("02-bayesian_stats/data/exp2.csv") %>%
  mutate(condition = condition == 'expansive') %>%
  group_by(participant)

dataset2
```



## Model 1

The first model is the BEST test model as described by Kruschke in the paper *Bayesian estimation supersedes the t-test*. In this model, $\beta$ indicates the mean difference in the outcome variable between the two groups (in this case, the percent change in the BART scores). We fit different priors on $\beta$ and set different weights on these priors to obtain our posterior estimate.

$$
\begin{align}
y_{i} &\sim \mathrm{T}(\nu, \mu, \sigma) \\
\mu &= \alpha_{0} + \beta * x_i \\
\sigma &= \sigma_{a} + \sigma_{b}*x_i \\
\beta &\sim \mathrm{N}(\mu_{0}, \sigma_{0}) \\
\sigma_a, \sigma_b &\sim \mathrm{Cauchy}(0, 2) \\
\nu &\sim \mathrm{exp}(30)
\end{align}
$$
```{r dataset2-model1-formula}

dataset2.brm.student.formula <- bf(
    bf(change ~ condition, sigma ~ condition), 
    family = student()
  )

get_prior(dataset2.brm.student.formula, data = dataset2)

```

```{r}

if(IF_RUN_MODEL){
  dataset2.brm.student = brm(
  dataset2.brm.student.formula,
  prior = c(
    prior(normal(0, 2), class = "b"),
    prior(cauchy(0, 2), class = "b", dpar = "sigma"),
    prior(exponential(30), class = "nu"),
    prior(student_t(3, 0, 5), class = "Intercept"),
    prior(student_t(3, 0, 2), class = "Intercept", dpar = "sigma")
  ), 
  data = dataset2,
  seed = 99,
  backend = "cmdstanr", #Fumeng: I have to use this as my backend, 'rstan' backend doesn't work on my laptops...
  chains = 4, 
  cores = 4,
  file = "02-bayesian_stats/rds/dataset2.brm.student.rds")
  
}else{
  dataset2.brm.student <- readRDS(file = "02-bayesian_stats/rds/dataset2.brm.student.rds")
}

```

```{r}
   summary(dataset2.brm.student)
```

```{r}

posterior_samples <- tibble(condition = c(TRUE, FALSE)) %>%
  add_fitted_draws(dataset2.brm.student, re_formula = NA) 


head(posterior_samples)

```
```{r plot-posterior_intervals}
posterior_samples %>%
  mean_qi() %>%
 mutate(term = if_else(condition, 'condition_graph',  'conditionno_graph')) %>%
  ggplot() +
  geom_pointrange(
    aes(
      x = term, 
      y = .value, 
      ymin = .lower, 
      ymax = .upper, 
      color = term
    ), position = position_dodge(width = 0.2)) +
    scale_color_brewer(palette = "Set2") +
    ylab('posterior change') + 
    ggtitle('posterior confidence intervals')

```

```{r plot-posterior_distribution}

posterior_samples %>%
  mutate(term = if_else(condition, 'condition_graph',  'conditionno_graph')) %>%
  ggplot(., aes(x = .value, fill = term)) +
  geom_density(alpha = 0.5, color = NA) +
  scale_fill_brewer(palette="Set2") +
  ggtitle('posterior distribution') + 
  coord_flip()

```





<!-- # Model 2 -->

<!-- Fumeng: I'm confused... It seems that Abhraneel has to generate some data in order to do poisson regression. -->
<!-- I would say we use the generated data from Dataset 2 or remove this...  -->



<!-- ```{r} -->
<!-- sim_trial = function(y) { -->
<!--   # let y be the actual number of trials that a participant will pump until -->
<!--   # p be the point of explosion for any given trial -->
<!--   p = sample(1:128, 1) -->
<!--   ifelse(p < y, p, y) -->
<!-- } -->

<!-- sim_exp = function(i, N = 10) { -->
<!--   trials = 1:N -->
<!--   map_dbl(trials, ~ sim_trial(i)) -->
<!-- } -->

<!-- sim_ = function(x, iter = 1e3) { -->
<!--   # here x is the averahe number of pumps by a participant -->
<!--   # we can perform a naive grid search approach -->
<!--   # let y >= x -->
<!--   for (i in ceiling(x):128) { -->
<!--     pumps = map( -->
<!--       1:iter,  -->
<!--       ~ mean(sim_exp(i)) # simulates one experiment and calculates the average number of pumps for that experiment -->
<!--     ) # repeats the simulation many times -->
<!--     if ((mean(map_dbl(pumps, mean))) > x) { -->
<!--       return(i) -->
<!--     } -->
<!--   } -->
<!-- } -->
<!-- ``` -->


<!-- ```{r, eval = FALSE} -->
<!-- df.gen = df %>% -->
<!--   mutate( -->
<!--     P10 = map(adjP10, sim_), -->
<!--     P20 = map(adjP20, sim_), -->
<!--     P30 = map(adjP30, sim_) -->
<!--   ) -->

<!-- saveRDS(df.gen, "~/Documents/Github/chi22-course/data/exp2-gen.rds") -->
<!-- ``` -->


<!-- ```{r} -->
<!-- df.gen = readRDS("~/Documents/Github/chi22-course/data/exp2-gen.rds") %>% -->
<!--   mutate( -->
<!--     P10 = map(P10, ~ unlist(ifelse(is.numeric(.), P10, 128))), -->
<!--     P20 = map(P20, ~ unlist(ifelse(is.numeric(.), P20, 128))), -->
<!--     P30 = map(P30, ~ unlist(ifelse(is.numeric(.), P30, 128))) -->
<!--   ) %>% -->
<!--   mutate( -->
<!--     trial_P10 = map(P10, ~ (sim_exp(.))), -->
<!--     trial_P20 = map(P20, ~ (sim_exp(.))), -->
<!--     trial_P30 = map(P30, ~ (sim_exp(.))) -->
<!--   ) %>% -->
<!--   pivot_longer( -->
<!--     cols = starts_with("trial"), -->
<!--     names_to = "trial", -->
<!--     names_prefix = "trial_P" -->
<!--   ) %>% -->
<!--   unnest(c(value)) %>% -->
<!--   group_by(participant) %>% -->
<!--   mutate(trial = row_number()) %>% -->
<!--   select(-c(starts_with("adjP"), "P10", "P20", "P30", "change", "orig")) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- # poisson analysis -->
<!-- fit.poiss = brm( -->
<!--   bf(value ~ condition),  -->
<!--   prior = c(prior(normal(0, 1), class = "b"), prior(student_t(3, 3.5, 1), class = "Intercept")),  -->
<!--   data = df.gen, family = poisson(),  -->
<!--   chains = 4, cores = 4) -->
<!-- ``` -->



