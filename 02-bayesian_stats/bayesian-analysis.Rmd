---
title: "chi22-course"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  html_document:
    highlight: tango
---

<style>
.sourceCode.r{
  background-color:#f7f8f9ff;
  font-family: Courier New;
  font-weight: bold
}


</style>


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(dplyr)
library(tibble)
library(purrr)
library(tidyr)
library(forcats)

library(broom)
library(broom.mixed)

library(modelr)

library(brms)
library(tidybayes)

library(ggdist)
library(bayesplot)
library(ggplot2)
library(knitr)

theme_set(theme_ggdist() + 
            theme(strip.background = element_blank()))

IF_RUN_MODEL <- T

set.seed(99) 

DARK_PURPLE <- '#351c75'
```


# Introduction

In this document, we will outline the Bayesian analogs of the statistical analyses described [here](https://github.com/chatchavan/CHI-Course-Transparent-Quant/blob/master/frequentist.Rmd) (and in the previous course lecture).


Helper functions.

```{r helper}

# this function extracts results from different models and generate results of the same format to be used in visualizations
tidy.wrapper = function(model) {
  if (class(model) == "lm") {
    tidy(model, conf.int = TRUE) %>%
      select(-c(statistic, p.value)) %>%
      mutate(model = "Frequentist") %>%
      select(model, everything())
  } else if (class(model) == "brmsfit") {
    tidy(model) %>%
      filter(effect == "fixed") %>%
      select(c(term:conf.high)) %>%
      mutate(model = "Bayesian") %>%
      select(model, everything())
  } else {
    stop("unknown model class")
  }
}
```

TODO: explain the dataset here


# Dataset 1

### Let's first load and look at the data in a table

```{r load-dataset}

# Fumemng -> Abhraneel I'm using the Rproj in the root folder, although my path is identical...

dataset = readr::read_csv("02-bayesian_stats/data/blinded.csv")
# dataset = readr::read_csv("~/Documents/Github/chi22-course/data/blinded.csv")

kable(head(dataset))

```  


```{r plot-dataset, fig.height = 3, fig.width = 7}
dataset %>% 
  mutate(effectiveness = fct_rev(factor(effectiveness, levels = 1:9))) %>%
  
  # stacked bar plot
  ggplot(aes(x = condition, fill = effectiveness)) +
  geom_bar(position = "stack", stat="count") +
  
  # plot data for different experiments as small multiples
  facet_wrap( ~ experiment) +
  
  # grey color scale is robust for colorblind
  scale_fill_brewer(palette="Greys", drop = FALSE) +
  
  # horizontal plot
  coord_flip() +
  
  # legend
  guides(fill = guide_legend(reverse = TRUE)) 
```

As we can see above, the original dataset contains results from four different experiments. For the purposes of this lecture, we will confine ourselves to the first experiment.

```{r filter-data}
exp1.data = dataset %>%
  filter(experiment == 1)

exp1.data
```


## Model 1. Wilcoxon signed rank test

This is a non-parametric test which we will skip for now. Although, there exists Bayesian non-parametric methods, they are more advanced for this lecture.

## Model 2. t-test

This is the linear model equivalent for the paired sample t-test

```{r dataset1-lm}
dataset1.lm.freqt <-
  lm(
    effectiveness ~ condition - 1, 
    data = exp1.data
  )
```


```{r dataset1-distribution}

  exp1.data %>%
     ggplot(., aes(x = effectiveness)) +
  geom_histogram(fill = '#351c75', color = NA)

```

```{r dataset1-bayesian-t-test-formula}
dataset1.brm.bayesiant.formula <- bf(
    effectiveness ~ condition - 1,
    family = student()
  )
```


```{r dataset1-bayesian-t-test-get-prior}

kable(as.tibble(get_prior(dataset1.brm.bayesiant.formula, data = exp1.data)))

```

```{r dataset1-bayesian-t-test-priors}
dataset1.brm.bayesiant.priors = c(
      prior(normal(0, 1), class = "b"), # there's a lot of data so even fairly "strong" priors are going to not matter so much here
      prior(student_t(3, 0, 1), class = "sigma")
      )

```

```{r dataset1-bayesian-t-test-run-prior-predictive-check, fig.height=4, fig.width=9}
dataset1.brm.bayesiant.priorchecks <-
  brm(
    dataset1.brm.bayesiant.formula,
    prior = dataset1.brm.bayesiant.priors,
    data = exp1.data,
    backend = "cmdstanr",
    sample_prior = "only",
    file = "02-bayesian_stats/rds/dataset1.brm.bayesiant.priorchecks.rds"
  )


dataset1.bayesiant.yprior <-
  posterior_predict(dataset1.brm.bayesiant.priorchecks)

ggplot() +
  geom_density(aes(x = dataset1.bayesiant.yprior),
               color = '#351c75',
               alpha = .5,
               size = 1) +
  xlab('prior draws') +
  ggtitle('prior preditive check')
```

```{r dataset1-bayesian-t-test-run}
dataset1.brm.bayesiant = 
  brm(dataset1.brm.bayesiant.formula,
    prior = dataset1.brm.bayesiant.priors,
    data = exp1.data,
    #You may not need this if rstan works with your computer
    backend = "cmdstanr", 
    #Save the model
    file = "02-bayesian_stats/rds/dataset1.brm.bayesiant.rds"
  )
```

```{r dataset1-bayesian-t-summary}
 summary(dataset1.brm.bayesiant)
```


```{r dataset1-diagnotics-1}
color_scheme_set(scheme = "purple")
plot(dataset1.brm.bayesiant)
```

```{r dataset1-posterior-diagnotics-2}

  dataset1.bayesiant.y <- exp1.data$effectiveness
  dataset1.bayesiant.yrep <- posterior_predict(dataset1.brm.bayesiant, draws = 50)
       
  kable(head(as_tibble(dataset1.bayesiant.yrep[,1:11])))            
```


```{r dataset1-posterior-diagnotics-3, fig.height=3, fig.width=10}
ppc_hist(y = dataset1.bayesiant.y,
         yrep = dataset1.bayesiant.yrep[1:8, ],
         binwidth = .5)

ppc_dens_overlay(y = dataset1.bayesiant.y,
                 yrep = dataset1.bayesiant.yrep[1:30, ])

ppc_stat_grouped(y = dataset1.bayesiant.y,
                 yrep = dataset1.bayesiant.yrep,
                 group = exp1.data$condition)
  
  
```



Compared to the frequentist estimates:

```{r dataset1-t-test-compare, fig.height=4, fig.width=10, warning=FALSE}
bind_rows(tidy.wrapper(dataset1.lm.freqt),
          tidy.wrapper(dataset1.brm.bayesiant)) %>%
  ggplot() +
  geom_pointrange(
    aes(
      x = model,
      y = estimate,
      ymin = conf.low,
      ymax = conf.high,
      color = term
    ),
    position = position_dodge(width = 0.2)
  ) +
  scale_color_brewer(palette = "Set1") +
  ylab('effectiveness') +
  scale_y_continuous(breaks = 1:9, limits = c(1, 9)) +
  coord_flip()
```




```{r dataset1-t-test-posterior-fitted}

dataset1.bayesiant.posterior_epred <- tibble(condition = c('graph', 'no_graph')) %>%
  add_epred_draws(dataset1.brm.bayesiant, re_formula = NA, allow_new_levels = FALSE) %>%
  ungroup()

kable(head(dataset1.bayesiant.posterior_epred))
```


```{r dataset1-bayesiant-posterior_comparison}
dataset1.bayesiant.posterior_comparison <- dataset1.bayesiant.posterior_epred %>%
  select(-c(.chain, .iteration, .row)) %>% 
  compare_levels(variable = .epred, by = condition)

kable(head(dataset1.bayesiant.posterior_comparison))


kable(dataset1.bayesiant.posterior_comparison %>%
           mean_qi(.epred))

```

```{r dataset1.bayesiant.diffci, fig.height=1, fig.width=5}

dataset1.bayesiant.posterior_comparison %>%
  median_qi(.epred) %>%
  ggplot() +
  geom_point(aes(x = .epred, y = condition), color = DARK_PURPLE, size = 3) +
  geom_errorbarh(
    aes(xmin = .lower, xmax = .upper, y = condition),
    color = DARK_PURPLE,
    alpha = .5,
    size = 2,
    height = 0
  ) +
  geom_vline(aes(xintercept = 0), linetype = "dashed", color = "gray") +
  coord_cartesian(ylim = c(0, 2), xlim = c(-1, 1))  +
  xlab('') + ylab('')
```



## Model 3. Ordinal Logistic Regression


```{r bayesian-ordinal-logistic-regression-formula}


dataset1.brm.olr.formula <- 
   bf(
    effectiveness ~ condition,
    family = cumulative("logit")
  )
```

```{r bayesian-ordinal-logistic-regression-prior}

get_prior(dataset1.brm.olr.formula, data = exp1.data)

dataset1.brm.olr.priors = c(
      prior(normal(0, 1), class = "b"),
      prior(student_t(3, 0, 1), class = "Intercept")
)

```

```{r bayesian-ordinal-logistic-regression-prior-checks, fig.height=4, fig.width=8}

dataset1.brm.olr.priorchecks <- brm(
    effectiveness ~ condition,
    prior = dataset1.brm.olr.priors,
    data = exp1.data,
    family= cumulative("logit"),
    backend = 'cmdstanr',
    sample_prior = 'only',
    file = "02-bayesian_stats/rds/dataset1.brm.bayesiant.priorchecks.rds"
    )



dataset1.olr.yprior <-
  posterior_predict(dataset1.brm.olr.priorchecks)


ggplot() +
  geom_histogram(aes(x = dataset1.olr.yprior),
               fill = '#351c75',
               alpha = .5,
               size = 1) +
  scale_x_continuous(breaks = 1:9, limits = c(1,9)) + 
  xlab('prior draws') +
  ggtitle('prior predictive check')

```

```{r bayesian-ordinal-logistic-regression-run-1}

dataset1.brm.olr1 = 
  brm(dataset1.brm.olr.formula,
    prior = dataset1.brm.olr.priors,
    data = exp1.data,
    backend = "cmdstanr",
    file = "02-bayesian_stats/rds/dataset1.brm.olr1.rds"
  )

summary(dataset1.brm.olr1)

```

```{r bayesian-ordinal-logistic-regression-run-2}

dataset1.brm.olr2 = 
  brm(dataset1.brm.olr.formula,
    prior = dataset1.brm.olr.priors,
    data = exp1.data,
    backend = "cmdstanr",
    warmup = 1500,
    iter = 2500,
    control = list(adapt_delta = 0.99, max_treedepth = 15),
    file = "02-bayesian_stats/rds/dataset1.brm.olr2.rds"
  )

summary(dataset1.brm.olr2)

```

```{r}
plot(dataset1.brm.olr2)
```


```{r dataset1-olr-posterior-checks, fig.height=3, fig.width=10}

dataset1.olr.y <- exp1.data$effectiveness
dataset1.olr.yrep <- posterior_predict(dataset1.brm.olr2)

ppc_hist(y = dataset1.olr.y,
         yrep = dataset1.olr.yrep[1000:1007,], binwidth = .5)

ppc_dens_overlay(y = dataset1.olr.y,
         yrep = dataset1.olr.yrep[2000:2030,])


ppc_stat_grouped(y = dataset1.olr.y,
         yrep = dataset1.olr.yrep, group = exp1.data$condition)

```

```{r dataset1-olr-epred-draws}

dataset1.olr.posterior_epred <-
  tibble(condition = c('graph', 'no_graph')) %>%
  add_epred_draws(dataset1.brm.olr2,
                  re_formula = NA,
                  allow_new_levels = FALSE) %>%
  ungroup()

kable(head(dataset1.olr.posterior_epred))

dataset1.olr.posterior_comparison <-
  dataset1.olr.posterior_epred %>%
  select(-c(.chain, .iteration, .row)) %>%
  group_by(.category) %>%
  compare_levels(variable = .epred, by = condition)

kable(head(dataset1.olr.posterior_comparison %>%
             mean_qi()))
```

```{r dataset1-olr-comparison, fig.height=3, fig.width=10}
dataset1.olr.posterior_comparison %>%
  mean_qi(.epred) %>%
  ggplot() +
  geom_point(aes(y = .epred, x = .category), size = 3, color = DARK_PURPLE) +
  geom_errorbar(
    aes(ymin = .lower, ymax = .upper, x = .category),
    width = 0,
    size = 2,
    color = DARK_PURPLE,
    alpha = .5
  ) +
  geom_hline(aes(yintercept = 0), linetype = "dashed", color = "gray") +
  xlab('') + ylab('no_graph - graph') +
  theme(axis.title.y = element_text(angle = 0, vjust = .5))
```
# Dataset 2


Load the data

```{r load-dataset-2}
dataset2 = readr::read_csv("02-bayesian_stats/data/exp2.csv") %>%
  mutate(condition = condition == 'expansive') %>%
  group_by(participant)

kable(head(dataset2))
```


```{r dataset2, fig.height=3, fig.width=7}
dataset2 %>%
  mutate(c = as.factor(condition)) %>%
  ggplot(aes(x = change)) +
  geom_histogram(aes(y = ..density..),
                 binwidth = 6,
                 fill = DARK_PURPLE,
                 color = 'white') +
  geom_density(size = 1, adjust = 1.5, color = 'lightgray') +
  scale_x_continuous(limits = c(-200, 200)) 
```


## Model 1

The first model is the BEST test model as described by Kruschke in the paper *Bayesian estimation supersedes the t-test*. In this model, $\beta$ indicates the mean difference in the outcome variable between the two groups (in this case, the percent change in the BART scores). We fit different priors on $\beta$ and set different weights on these priors to obtain our posterior estimate.

$$
\begin{align}
y_{i} &\sim \mathrm{T}(\nu, \mu, \sigma) \\
\mu &= \alpha_{0} + \beta * x_i \\
\sigma &= \sigma_{a} + \sigma_{b}*x_i \\
\beta &\sim \mathrm{N}(\mu_{0}, \sigma_{0}) \\
\sigma_a, \sigma_b &\sim \mathrm{Cauchy}(0, 2) \\
\nu &\sim \mathrm{exp}(1/30)
\end{align}
$$

```{r dataset2-model1-formula}

dataset2.brm.student.formula <- bf(
    change ~ condition, 
    sigma ~ condition, 
    family = student()
  )

kable(head(as_tibble(get_prior(dataset2.brm.student.formula, data = dataset2))))

```


```{r dataset2-bayesiant-prior-checkes}
dataset2.brm.student.priorchecks = brm(
  dataset2.brm.student.formula,
  prior = c(
    prior(normal(0, 2), class = "b"),
    prior(cauchy(0, 2), class = "b", dpar = "sigma"),
    prior(exponential(0.033), class = "nu"),
    prior(student_t(3, 0, 5), class = "Intercept"),
    prior(student_t(3, 0, 2), class = "Intercept", dpar = "sigma")
  ),
  data = dataset2,
  backend = "cmdstanr",
  sample_prior = 'only',
  file = "02-bayesian_stats/rds/dataset2.brm.student.priorchecks.rds"
)

# dataset2.student.yprior <-
#   posterior_predict(dataset2.brm.student.priorchecks)

# ggplot() +
#   geom_density(
#     aes(x = dataset2.student.yprior),
#     color = '#351c75',
#     alpha = .5,
#     size = 1
#   ) +
#   xlab('prior draws') +
#   ggtitle('prior preditive check')

```


```{r dataset2-bayesiant}
dataset2.brm.student = brm(
 bf(change ~ condition, 
 sigma ~ condition,
 family = student()),
 prior = c(
   prior(normal(0, 2), class = "b"),
   prior(cauchy(0, 2), class = "b", dpar = "sigma"),
   prior(exponential(.033), class = "nu"),
   prior(student_t(3, 0, 5), class = "Intercept"),
   prior(student_t(3, 0, 2), class = "Intercept", dpar = "sigma")
 ), 
 data = dataset2,
 backend = "cmdstanr",
 file = "02-bayesian_stats/rds/dataset2.brm.student.rds"
)

get_priors(dataset2.brm.student)
```


```{r dataset2-brm-student-summary}
summary(dataset2.brm.student)

```

```{r dataset2-diagnotics-1, fig.height=8, fig.width=10}

plot(dataset2.brm.student)

```

```{r dataset2-posterior-diagnotics-2}

dataset2.student.y <- dataset2.brm.student$data$change
dataset2.student.yrep <- posterior_predict(dataset2.brm.student)

dataset2.student.epred <- tibble(condition = c(TRUE, FALSE)) %>%
  add_epred_draws(dataset2.brm.student, re_formula = NA, allow_new_levels = TRUE) %>%
  ungroup()
```



```{r dataset2-posterior-diagnotics-3, fig.height=3, fig.width=10}
ppc_hist(y = dataset2.student.y,
         yrep = dataset2.student.yrep[100:107,], binwidth = 10)


ppc_dens_overlay(y = dataset2.student.y,
         yrep = dataset2.student.yrep[2000:2030,])


ppc_stat_grouped(y = dataset2.student.y,
         yrep = dataset2.student.yrep,
         group = dataset2$condition,
         binwidth = 5)
```



```{r dataset2-student-posterior-fitted}

dataset2.student.epred_comparison <- tibble(condition = c(TRUE, FALSE)) %>%
 add_epred_draws(dataset2.brm.student, re_formula = NA, allow_new_levels = FALSE) %>%
 ungroup() %>%
 select(-c(.chain, .iteration, .row)) %>% 
 compare_levels(variable = .epred, by = condition) %>%
 rename(diff = .epred)


kable(head(dataset2.student.epred_comparison))


```

```{r dataset2.studenyt.diffci, fig.height=1, fig.width=5}
dataset2.student.epred_comparison %>%
  select(diff) %>%
  mean_qi() %>%
ggplot() +
  geom_point(aes(x = diff, y = condition), size = 3, color = DARK_PURPLE) + 
  geom_errorbarh(
    aes(xmin = .lower, xmax = .upper, y = condition),
    height = 0,
    color = DARK_PURPLE,
    alpha = .5,
    size = 2
  ) +
  geom_vline(aes(xintercept = 0), linetype = "dashed", color = "gray") + 
  coord_cartesian(ylim = c(0, 2), xlim = c(-5, 5))  + 
  scale_y_discrete(label = c('expansive - not expansive')) + 
  xlab('')  + ylab('')
```





<!-- # Model 2 -->

<!-- Fumeng: I'm confused... It seems that Abhraneel has to generate some data in order to do poisson regression. -->
<!-- I would say we use the generated data from Dataset 2 or remove this...  -->



<!-- ```{r} -->
<!-- sim_trial = function(y) { -->
<!--   # let y be the actual number of trials that a participant will pump until -->
<!--   # p be the point of explosion for any given trial -->
<!--   p = sample(1:128, 1) -->
<!--   ifelse(p < y, p, y) -->
<!-- } -->

<!-- sim_exp = function(i, N = 10) { -->
<!--   trials = 1:N -->
<!--   map_dbl(trials, ~ sim_trial(i)) -->
<!-- } -->

<!-- sim_ = function(x, iter = 1e3) { -->
<!--   # here x is the averahe number of pumps by a participant -->
<!--   # we can perform a naive grid search approach -->
<!--   # let y >= x -->
<!--   for (i in ceiling(x):128) { -->
<!--     pumps = map( -->
<!--       1:iter,  -->
<!--       ~ mean(sim_exp(i)) # simulates one experiment and calculates the average number of pumps for that experiment -->
<!--     ) # repeats the simulation many times -->
<!--     if ((mean(map_dbl(pumps, mean))) > x) { -->
<!--       return(i) -->
<!--     } -->
<!--   } -->
<!-- } -->
<!-- ``` -->


<!-- ```{r, eval = FALSE} -->
<!-- df.gen = df %>% -->
<!--   mutate( -->
<!--     P10 = map(adjP10, sim_), -->
<!--     P20 = map(adjP20, sim_), -->
<!--     P30 = map(adjP30, sim_) -->
<!--   ) -->

<!-- saveRDS(df.gen, "~/Documents/Github/chi22-course/data/exp2-gen.rds") -->
<!-- ``` -->


<!-- ```{r} -->
<!-- df.gen = readRDS("~/Documents/Github/chi22-course/data/exp2-gen.rds") %>% -->
<!--   mutate( -->
<!--     P10 = map(P10, ~ unlist(ifelse(is.numeric(.), P10, 128))), -->
<!--     P20 = map(P20, ~ unlist(ifelse(is.numeric(.), P20, 128))), -->
<!--     P30 = map(P30, ~ unlist(ifelse(is.numeric(.), P30, 128))) -->
<!--   ) %>% -->
<!--   mutate( -->
<!--     trial_P10 = map(P10, ~ (sim_exp(.))), -->
<!--     trial_P20 = map(P20, ~ (sim_exp(.))), -->
<!--     trial_P30 = map(P30, ~ (sim_exp(.))) -->
<!--   ) %>% -->
<!--   pivot_longer( -->
<!--     cols = starts_with("trial"), -->
<!--     names_to = "trial", -->
<!--     names_prefix = "trial_P" -->
<!--   ) %>% -->
<!--   unnest(c(value)) %>% -->
<!--   group_by(participant) %>% -->
<!--   mutate(trial = row_number()) %>% -->
<!--   select(-c(starts_with("adjP"), "P10", "P20", "P30", "change", "orig")) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- # poisson analysis -->
<!-- fit.poiss = brm( -->
<!--   bf(value ~ condition),  -->
<!--   prior = c(prior(normal(0, 1), class = "b"), prior(student_t(3, 3.5, 1), class = "Intercept")),  -->
<!--   data = df.gen, family = poisson(),  -->
<!--   chains = 4, cores = 4) -->
<!-- ``` -->



