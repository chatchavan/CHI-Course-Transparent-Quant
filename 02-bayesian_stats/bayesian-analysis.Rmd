---
title: "chi22-course"
author: "Abhraneel Sarma"
date: "3/3/2022"
output: 
  html_document:
    highlight: tango
---

<style>
.sourceCode.r{
  background-color:#f7f8f9ff
}
</style>


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(dplyr)
library(tibble)
library(purrr)
library(tidyr)
library(forcats)

library(broom)
library(broom.mixed)

library(modelr)

library(brms)
library(tidybayes)

library(ggdist)
library(bayesplot)
library(ggplot2)
library(knitr)

theme_set(theme_ggdist() + 
            theme(strip.background = element_blank()))

IF_RUN_MODEL <- T
```


# Introduction

In this document, we will outline the Bayesian analogs of the statistical analyses described [here](https://github.com/chatchavan/CHI-Course-Transparent-Quant/blob/master/frequentist.Rmd) (and in the previous course lecture).


Helper functions.

```{r helper}

# this function extracts results from different models and generate results of the same format to be used in visualizations
tidy.wrapper = function(model) {
  if (class(model) == "lm") {
    tidy(model, conf.int = TRUE) %>%
      select(-c(statistic, p.value)) %>%
      mutate(model = "Frequentist") %>%
      select(model, everything())
  } else if (class(model) == "brmsfit") {
    tidy(model) %>%
      filter(effect == "fixed") %>%
      select(c(term:conf.high)) %>%
      mutate(model = "Bayesian") %>%
      select(model, everything())
  } else {
    stop("unknown model class")
  }
}
```

TODO: explain the dataset here


# Dataset 1

### Let's first load and look at the data in a table

```{r load-dataset}

# Fumemng -> Abhraneel I'm using the Rproj in the root folder, although my path is identical...

dataset = readr::read_csv("02-bayesian_stats/data/blinded.csv")
# dataset = readr::read_csv("~/Documents/Github/chi22-course/data/blinded.csv")

kable(head(dataset))

```  


```{r plot-dataset, fig.height = 3, fig.width = 7}
dataset %>% 
  mutate(effectiveness = fct_rev(factor(effectiveness, levels = 1:9))) %>%
  
  # stacked bar plot
  ggplot(aes(x = condition, fill = effectiveness)) +
  geom_bar(position = "stack", stat="count") +
  
  # plot data for different experiments as small multiples
  facet_wrap( ~ experiment) +
  
  # grey color scale is robust for colorblind
  scale_fill_brewer(palette="Greys", drop = FALSE) +
  
  # horizontal plot
  coord_flip() +
  
  # legend
  guides(fill = guide_legend(reverse = TRUE)) 
```

As we can see above, the original dataset contains results from four different experiments. For the purposes of this lecture, we will confine ourselves to the first experiment.

```{r filter-data}
exp1.data = dataset %>%
  filter(experiment == 1)

exp1.data
```


## Model 1. Wilcoxon signed rank test

This is a non-parametric test which we will skip for now. Although, there exists Bayesian non-parametric methods, they are more advanced for this lecture.

## Model 2. t-test

This is the linear model equivalent for the paired sample t-test

```{r dataset1-lm}
dataset1.lm.freqt <-
  lm(
    effectiveness ~ condition - 1, 
    data = exp1.data
  )
```


```{r dataset1-bayesian-t-test-formula}
dataset1.brm.bayesiant.formula <- bf(
    effectiveness ~ condition - 1,
    family = student()
  )
```


```{r dataset1-bayesian-t-test-get-prior}

kable(as.tibble(get_prior(dataset1.brm.bayesiant.formula, data = exp1.data)))

```

```{r dataset1-bayesian-t-test-run}
dataset1.brm.bayesiant.priors = c(
      prior(normal(0, 1), class = "b"), # there's a lot of data so even fairly "strong" priors are going to not matter so much here
      prior(student_t(3, 0, 1), class = "sigma")
      )

if(IF_RUN_MODEL){
  dataset1.brm.bayesiant = 
  brm(dataset1.brm.bayesiant.formula,
    prior = dataset1.brm.bayesiant.priors,
    data = exp1.data,
    seed = 99,
    backend = "cmdstanr", #Fumeng: I have to use this as my backend. 'rstan' backend doesn't work on my laptops...
    chains = 4, 
    cores = 4,
    file = "02-bayesian_stats/rds/dataset1.brm.bayesiant.rds"
  )
} else{
    dataset1.brm.bayesiant <- readRDS(file = "02-bayesian_stats/rds/dataset1.brm2.bayesiant.rds")
}

```

```{r}
 summary(dataset1.brm.bayesiant)
```
```{r dataset1-diagnotics-1}
color_scheme_set(scheme = "purple")
plot(dataset1.brm.bayesiant)

```

```{r dataset1-posterior-diagnotics-2}

  dataset1.bayesiant.y <- dataset1.brm.bayesiant$data$effectiveness
  dataset1.bayesiant.yrep <- posterior_predict(dataset1.brm.bayesiant, draws = 50)
       
  kable(head(as_tibble(dataset1.bayesiant.yrep[,1:11])))            
```


```{r dataset1-posterior-diagnotics-3, fig.height=4, fig.width=8}
ppc_hist(y = dataset1.bayesiant.y,
         yrep = dataset1.bayesiant.yrep[1:8, ],
         binwidth = .5)

ppc_dens_overlay(y = dataset1.bayesiant.y,
                 yrep = dataset1.bayesiant.yrep[1:30, ])
  
  
```



Compared to the frequentist estimates:

```{r dataset1-t-test-compare, fig.height=4, fig.width=10, warning=FALSE}
bind_rows(tidy.wrapper(dataset1.lm.freqt),
          tidy.wrapper(dataset1.brm.bayesiant)) %>%
  ggplot() +
  geom_pointrange(
    aes(
      x = model,
      y = estimate,
      ymin = conf.low,
      ymax = conf.high,
      color = term
    ),
    position = position_dodge(width = 0.2)
  ) +
  scale_color_brewer(palette = "Set1") +
  ylab('effectiveness') +
  scale_y_continuous(breaks = 1:9, limits = c(1, 9)) +
  coord_flip()
```




```{r dataset1-t-test-posterior-fitted}

dataset1.bayesiant.posterior_fitted <- tibble(condition = c('graph', 'no_graph')) %>%
  add_fitted_draws(dataset1.brm.bayesiant, re_formula = NA, allow_new_levels = F) %>%
  ungroup() 
  
#fitted_values <- fitted(dataset1.brm.bayesiant)

kable(head(dataset1.bayesiant.posterior_fitted))
```


```{r}
dataset1.bayesiant.posterior_comparison <-
  dataset1.bayesiant.posterior_fitted %>%
  select(-c(.chain, .iteration, .row)) %>%
  spread(key = condition, value = .value) %>%
  mutate(diff = graph - no_graph) 
```

```{r dataset1.bayesiant.diffci, fig.height=2, fig.width=10}


kable(dataset1.bayesiant.posterior_comparison %>%
  select(diff) %>%
  mean_qi() 
)

dataset1.bayesiant.posterior_comparison %>%
  select(diff) %>%
  mean_qi() %>%
ggplot() +
  geom_point(aes(x = diff, y = 'graph - no graph'), size = 2) + 
  geom_errorbarh(
    aes(xmin = .lower, xmax = .upper, y = 'graph - no graph'),
    height = 0
  ) +
  geom_vline(aes(xintercept = 0), linetype = "dashed", color = "gray") + 
  coord_cartesian(ylim = c(0, 2), xlim = c(-1, 1))  +
  xlab('difference') + ylab('')
```



## Model 3. Ordinal Logistic Regression


```{r ordinal-logistic-regression}

test <- brm(effectiveness ~ condition,
    data = exp1.data,
    family=cumulative("logit"),
    warmup = 250,#2500
    iter = 350,#3500
    backend = 'cmdstanr'
    )

# TODO priors

summary(test)

```

```{r}
#TODO

posterior_samples <- tibble(condition = c('graph', 'no_graph')) %>%
     add_fitted_draws(test, re_formula = NA) 


posterior_samples
```


```{r}

posterior_samples %>% 
  ggplot(., aes(x = .value)) +
  geom_histogram() +
  facet_grid(.~condition)

```
# Dataset 2


Load the data

```{r load-dataset-2}
dataset2 = readr::read_csv("02-bayesian_stats/data/exp2.csv") %>%
  mutate(condition = condition == 'expansive') %>%
  group_by(participant)

kable(head(dataset2))
```



## Model 1

The first model is the BEST test model as described by Kruschke in the paper *Bayesian estimation supersedes the t-test*. In this model, $\beta$ indicates the mean difference in the outcome variable between the two groups (in this case, the percent change in the BART scores). We fit different priors on $\beta$ and set different weights on these priors to obtain our posterior estimate.

$$
\begin{align}
y_{i} &\sim \mathrm{T}(\nu, \mu, \sigma) \\
\mu &= \alpha_{0} + \beta * x_i \\
\sigma &= \sigma_{a} + \sigma_{b}*x_i \\
\beta &\sim \mathrm{N}(\mu_{0}, \sigma_{0}) \\
\sigma_a, \sigma_b &\sim \mathrm{Cauchy}(0, 2) \\
\nu &\sim \mathrm{exp}(1/30)
\end{align}
$$

```{r dataset2-model1-formula}

dataset2.brm.student.formula <- bf(
    change ~ condition, 
    sigma ~ condition, 
    family = student()
  )

kable(head(as_tibble(get_prior(dataset2.brm.student.formula, data = dataset2))))

```

```{r dataset2-bayesiant}

if(IF_RUN_MODEL){
  dataset2.brm.student = brm(
  dataset2.brm.student.formula,
  prior = c(
    prior(normal(0, 2), class = "b"),
    prior(cauchy(0, 2), class = "b", dpar = "sigma"),
    prior(exponential(0.033), class = "nu"), # Do I misunderstand something or this prior is really exp(30)?
    #prior(cauchy(0, 1), class = "nu"),
    prior(student_t(3, 0, 5), class = "Intercept"),
    prior(student_t(3, 0, 2), class = "Intercept", dpar = "sigma")
  ), 
  data = dataset2,
  seed = 99,
  backend = "cmdstanr", #Fumeng: I have to use this as my backend. 'rstan' backend doesn't work on my laptops...
  chains = 4, 
  cores = 4,
  file = "02-bayesian_stats/rds/dataset2.brm.student.rds")
}else{
  dataset2.brm.student <- readRDS(file = "02-bayesian_stats/rds/dataset2.brm.student.rds")
  # dataset2.brm.student <- readRDS(file = "session-3-vis/data/dataset2.brm.student.rds")
}

```


```{r}
  summary(dataset2.brm.student)
```

```{r dataset2-diagnotics-1, fig.height=8, fig.width=10}

plot(dataset2.brm.student)

```

```{r dataset2-posterior-diagnotics-2}

dataset2.student.y <- dataset2.brm.student$data$change
dataset2.student.yrep <- posterior_predict(dataset2.brm.student, draws = 50)

min(dataset2.student.yrep)
max(dataset2.student.yrep)
```



```{r dataset2-posterior-diagnotics-3, fig.height=3, fig.width=10}
ppc_hist(y = dataset2.student.y,
         yrep = dataset2.student.yrep[100:107,], binwidth = 10)


ppc_dens_overlay(y = dataset2.student.y,
         yrep = dataset2.student.yrep[100:130,])


ppc_stat(y = dataset2.student.y,
         yrep = dataset2.student.yrep)
```



```{r dataset2-student-posterior-fitted}

dataset2.student.posterior_fitted_comparison <- tibble(condition = c(TRUE, FALSE)) %>%
  add_fitted_draws(dataset2.brm.student, re_formula = NA, allow_new_levels = F) %>%
  ungroup() %>%
  select(-c(.chain, .iteration, .row)) %>% 
  spread(key = condition, value = .value) %>%
  mutate(diff = `TRUE` - `FALSE`) 
  

kable(head(dataset2.student.posterior_fitted_comparison))
```


```{r dataset2.studenyt.diffci, fig.height=2, fig.width=10}
dataset2.student.posterior_fitted_comparison %>%
  select(diff) %>%
  mean_qi() %>%
ggplot() +
  geom_point(aes(x = diff, y = 'TRUE - FALSE'), size = 2) + 
  geom_errorbarh(
    aes(xmin = .lower, xmax = .upper, y = 'TRUE - FALSE'),
    height = 0
  ) +
  geom_vline(aes(xintercept = 0), linetype = "dashed", color = "gray") + 
  coord_cartesian(ylim = c(0, 2), xlim = c(-5, 5))  +
  xlab('difference') + ylab('') 
```





<!-- # Model 2 -->

<!-- Fumeng: I'm confused... It seems that Abhraneel has to generate some data in order to do poisson regression. -->
<!-- I would say we use the generated data from Dataset 2 or remove this...  -->



<!-- ```{r} -->
<!-- sim_trial = function(y) { -->
<!--   # let y be the actual number of trials that a participant will pump until -->
<!--   # p be the point of explosion for any given trial -->
<!--   p = sample(1:128, 1) -->
<!--   ifelse(p < y, p, y) -->
<!-- } -->

<!-- sim_exp = function(i, N = 10) { -->
<!--   trials = 1:N -->
<!--   map_dbl(trials, ~ sim_trial(i)) -->
<!-- } -->

<!-- sim_ = function(x, iter = 1e3) { -->
<!--   # here x is the averahe number of pumps by a participant -->
<!--   # we can perform a naive grid search approach -->
<!--   # let y >= x -->
<!--   for (i in ceiling(x):128) { -->
<!--     pumps = map( -->
<!--       1:iter,  -->
<!--       ~ mean(sim_exp(i)) # simulates one experiment and calculates the average number of pumps for that experiment -->
<!--     ) # repeats the simulation many times -->
<!--     if ((mean(map_dbl(pumps, mean))) > x) { -->
<!--       return(i) -->
<!--     } -->
<!--   } -->
<!-- } -->
<!-- ``` -->


<!-- ```{r, eval = FALSE} -->
<!-- df.gen = df %>% -->
<!--   mutate( -->
<!--     P10 = map(adjP10, sim_), -->
<!--     P20 = map(adjP20, sim_), -->
<!--     P30 = map(adjP30, sim_) -->
<!--   ) -->

<!-- saveRDS(df.gen, "~/Documents/Github/chi22-course/data/exp2-gen.rds") -->
<!-- ``` -->


<!-- ```{r} -->
<!-- df.gen = readRDS("~/Documents/Github/chi22-course/data/exp2-gen.rds") %>% -->
<!--   mutate( -->
<!--     P10 = map(P10, ~ unlist(ifelse(is.numeric(.), P10, 128))), -->
<!--     P20 = map(P20, ~ unlist(ifelse(is.numeric(.), P20, 128))), -->
<!--     P30 = map(P30, ~ unlist(ifelse(is.numeric(.), P30, 128))) -->
<!--   ) %>% -->
<!--   mutate( -->
<!--     trial_P10 = map(P10, ~ (sim_exp(.))), -->
<!--     trial_P20 = map(P20, ~ (sim_exp(.))), -->
<!--     trial_P30 = map(P30, ~ (sim_exp(.))) -->
<!--   ) %>% -->
<!--   pivot_longer( -->
<!--     cols = starts_with("trial"), -->
<!--     names_to = "trial", -->
<!--     names_prefix = "trial_P" -->
<!--   ) %>% -->
<!--   unnest(c(value)) %>% -->
<!--   group_by(participant) %>% -->
<!--   mutate(trial = row_number()) %>% -->
<!--   select(-c(starts_with("adjP"), "P10", "P20", "P30", "change", "orig")) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- # poisson analysis -->
<!-- fit.poiss = brm( -->
<!--   bf(value ~ condition),  -->
<!--   prior = c(prior(normal(0, 1), class = "b"), prior(student_t(3, 3.5, 1), class = "Intercept")),  -->
<!--   data = df.gen, family = poisson(),  -->
<!--   chains = 4, cores = 4) -->
<!-- ``` -->



