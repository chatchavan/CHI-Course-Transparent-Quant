---
title: "chi22-course"
author: "Abhraneel Sarma"
date: "3/3/2022"
output: html_document
---



```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(dplyr)
library(tibble)
library(purrr)
library(tidyr)
library(forcats)

library(broom)
library(broom.mixed)

library(modelr)

library(brms)
library(tidybayes)

library(ggdist)
library(ggplot2)

theme_set(theme_ggdist())

IF_RUN_MODEL <- T
```


# Introduction

In this document, we will outline the Bayesian analogs of the statistical analyses described [here](https://github.com/chatchavan/CHI-Course-Transparent-Quant/blob/master/frequentist.Rmd) (and in the previous course lecture).


Helper functions.

```{r helper}

# this function extracts results from different models and generate results of the same format to be used in visualizations
tidy.wrapper = function(model) {
  if (class(model) == "lm") {
    tidy(result_ttest, conf.int = TRUE) %>%
      select(-c(statistic, p.value)) %>%
      mutate(model = "Frequentist") %>%
      select(model, everything())
  } else if (class(model) == "brmsfit") {
    tidy(result_ttest.bayesian) %>%
      filter(effect == "fixed") %>%
      select(c(term:conf.high)) %>%
      mutate(model = "Bayesian") %>%
      select(model, everything())
  } else {
    stop("unknown model class")
  }
}
```

TODO: explain the dataset here


# Dataset 1

### Let's first load and look at the data in a table

```{r load-dataset}

# Fumemng -> Abhraneel I'm using the Rproj in the root folder, although my is identical...

dataset = readr::read_csv("02-bayesian_stats/data/blinded.csv")
# dataset = readr::read_csv("~/Documents/Github/chi22-course/data/blinded.csv")

dataset

```  


```{r plot-dataset, fig.height = 3, fig.width = 7}
dataset %>% 
  mutate(effectiveness = fct_rev(factor(effectiveness, levels = 1:9))) %>%
  
  # stacked bar plot
  ggplot(aes(x = condition, fill = effectiveness)) +
  geom_bar(position = "stack", stat="count") +
  
  # plot data for different experiments as small multiples
  facet_wrap( ~ experiment) +
  
  # grey color scale is robust for colorblind
  scale_fill_brewer(palette="Greys", drop = FALSE) +
  
  # horizontal plot
  coord_flip() +
  
  # legend
  guides(fill = guide_legend(reverse = TRUE)) 
```

As we can see above, the original dataset contains results from four different experiments. For the purposes of this lecture, we will confine ourselves to the first experiment.

```{r filter-data}
exp1.data = dataset %>%
  filter(experiment == 1)

exp1.data
```


## Model 1. Wilcoxon signed rank test

This is a non-parametric test which we will skip for now. Although, there exists Bayesian non-parametric methods, they are more advanced for this lecture.

## Model 2. t-test

This is the linear model equivalent for the paired sample t-test

```{r dataset1-lm}
dataset1.m2.freqt =
  lm(
    effectiveness ~ condition - 1, 
    data = exp1.data
  )
```


```{r dataset1-bayesian-t-test-formula}
dataset1.m2.bayesiant.formula <- bf(
    effectiveness ~ condition - 1,
    family = student()
  )
```


```{r dataset1-bayesian-t-test-get-prior}

get_prior(dataset1.m2.bayesiant.formula, data = exp1.data)

```

```{r dataset1-bayesian-t-test-run}

if(IF_RUN_MODEL){
  dataset1.m2 = 
  brm(dataset1.m2.bayesiant.formula,
      prior = c(
      prior(normal(0, 1), class = "b"), # there's a lot of data so even fairly "strong" priors are going to not matter so much here
      prior(student_t(3, 0, 1), class = "sigma")),
    data = exp1.data,
    seed = 99,
    backend = "cmdstanr", #Fumeng: I have to use this as my backend, 'rstan' backend doesn't work on my laptops...
    chains = 4, 
    cores = 4,
    file = "02-bayesian_stats/rds/dataset1.m2.bayesiant.rds"
  )

} else{
    dataset1.m2 <- readRDS(file = "02-bayesian_stats/rds/dataset1.m2.bayesiant.rds")
}




```

Next, we visualise the results, along with a side-by-side comparison of the frequentist estimates:

```{r dataset1-t-test-compare, echo = FALSE, warning = FALSE}
bind_rows(
  tidy.wrapper(dataset1.m2.freqt),
  tidy.wrapper(dataset1.m2.bayesiant)
) %>%
  ggplot() +
  geom_pointrange(
    aes(
      x = term, 
      y = estimate, 
      ymin = conf.low, 
      ymax = conf.high, 
      color = model
    ), position = position_dodge(width = 0.2)) +
    scale_color_brewer(palette = "Set2")
```



## Model 3. Ordinal Logistic Regression


```{r ordinal-logistic-regression}


```



# Dataset 2


Load the data

```{r load-dataset-2}
dataset2 = readr::read_csv("02-bayesian_stats/data/exp2.csv") %>%
  mutate(condition = condition == 'expansive') %>%
  group_by(participant)

dataset2
```



## Model 1

The first model is the BEST test model as described by Kruschke in the paper *Bayesian estimation supersedes the t-test*. In this model, $\beta$ indicates the mean difference in the outcome variable between the two groups (in this case, the percent change in the BART scores). We fit different priors on $\beta$ and set different weights on these priors to obtain our posterior estimate.

$$
\begin{align}
y_{i} &\sim \mathrm{T}(\nu, \mu, \sigma) \\
\mu &= \alpha_{0} + \beta * x_i \\
\sigma &= \sigma_{a} + \sigma_{b}*x_i \\
\beta &\sim \mathrm{N}(\mu_{0}, \sigma_{0}) \\
\sigma_a, \sigma_b &\sim \mathrm{Cauchy}(0, 2) \\
\nu &\sim \mathrm{exp}(30)
\end{align}
$$
```{r dataset2-model1-formula}

dataset2.m1.formula <- bf(
    bf(change ~ condition, sigma ~ condition), 
    family = student()
  )

get_prior(dataset2.m1.formula, data = dataset2)

```

```{r, eval = FALSE}

if(IF_RUN_MODEL){
  dataset2.m1 = brm(
  dataset2.m1.formula,
  prior = c(
    prior(normal(0, 2), class = "b"),
    prior(cauchy(0, 2), class = "b", dpar = "sigma"),
    prior(exponential(30), class = "nu"),
    prior(student_t(3, 0, 5), class = "Intercept"),
    prior(student_t(3, 0, 2), class = "Intercept", dpar = "sigma")
  ), 
  data = dataset2,
  seed = 99,
  backend = "cmdstanr", #Fumeng: I have to use this as my backend, 'rstan' backend doesn't work on my laptops...
  chains = 4, 
  cores = 4,
  file = "02-bayesian_stats/rds/dataset2.m1.rds")
  
}else{
  dataset2.m1 <- readRDS(file = "02-bayesian_stats/rds/dataset2.m1.rds")
}

```

```{r}
   summary(dataset2.m1)
```

```{r}

posterior_samples <- tibble(condition = c(TRUE, FALSE)) %>%
  add_fitted_draws(fit.brm, re_formula = NA, value = "posterior_change") %>%
  select(-.chain, -.iteration)


head(posterior_samples)

```
```{r plot-posterior_intervals}
tidy.wrapper(dataset2.m1.brm) %>%
  ggplot() +
  geom_pointrange(
    aes(
      x = term, 
      y = estimate, 
      ymin = conf.low, 
      ymax = conf.high, 
      color = term
    ), position = position_dodge(width = 0.2)) +
    scale_color_brewer(palette = "Set2") +
    ggtitle('posterior confidence intervals')

```

```{r plot-posterior_distribution}

posterior_samples %>%
  mutate(term = if_else(condition, 'condition_graph',  'conditionno_graph')) %>%
  ggplot(., aes(x = posterior_change, fill = term)) +
  geom_density(alpha = 0.5, color = NA) +
  scale_fill_brewer(palette="Set2") +
  ggtitle('posterior distribution')

```





# Model 2

Fumeng's I'm confused... It seems that Abhraneel has to generate some data in order to do poisson..
I would say we use the generated data from Dataset 2 or remove this... 

```{r}
# poisson analysis
fit.poiss = brm(
  bf(value ~ condition), 
  prior = c(prior(normal(0, 1), class = "b"), prior(student_t(3, 3.5, 1), class = "Intercept")), 
  data = df.gen, family = poisson(), 
  chains = 4, cores = 4)
```




