---
title: "Introduction to Transparent Bayesian Data Analysis (chi2023-course)"
date: "`r format(Sys.time(), '%d %B, %Y')`"
author: Abhraneel Sarma and Fumeng Yang
output: 
  html_document: 
    css: "CHI23course-style.css"
    toc_depth: 2
    toc: yes
    toc_float:
      collapsed: no
      smooth_scroll: no
    df_print: kable
---


```{r knit-github, eval=FALSE,echo=FALSE,include=FALSE}
# compile for github, you can ignore this
library(rmarkdown)
render("bayesian-analysis.Rmd", md_document(variant = "gfm"), 
       knit_root_dir = "/Users/fm/Documents/Github/CHI-Course-Transparent-Quant")
```

```{r setup, include=FALSE}
rm(list = ls(all.names = TRUE))
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, fig.width = 10, fig.height = 6)
```

# Introduction

In this document, we will outline the Bayesian analogs of the statistical analyses described in lecture 1 ([Github code](https://github.com/chatchavan/CHI-Course-Transparent-Quant-Lecture-1)).

# Load packages

```{r message=FALSE, warning=FALSE}
library(dplyr)
library(tibble)
library(purrr)
library(tidyr)
library(forcats)
library(gtools)
library(patchwork)
library(broom)
library(broom.mixed)
library(modelr)
library(brms)
library(tidybayes)
library(ggdist)
library(bayesplot)
library(ggplot2)
library(knitr)
BRM_BACKEND <- ifelse(require("cmdstanr"), 'cmdstanr', 'rstan')
```

```{r include=FALSE}
# specify  theme colors
theme_green = '#20a598'
theme_blue = '#4574bf'
theme_yellow = '#fbc63d'
theme_red = '#e2524b'
scale_color_theme = \(...) scale_color_manual(..., 
  values = c('prior' = theme_yellow,
             'expansive' = theme_blue, 
             'posterior' = theme_green,
             'constrictive' = '#888888'),
  guide = "none",
  aesthetics = c("color", "fill")
)
# set up the global theme
theme_set(theme_ggdist() + 
          theme(strip.background = element_blank(),
               plot.title = element_text(hjust = .5)))
# We also define some ggplot styles
theme_density = theme(
    axis.text.y = element_text(colour = "#ffffff"),
    axis.title.y = element_blank(),
    axis.line.y = element_blank(),
    axis.ticks.y = element_blank(),
    axis.text.x = element_text(colour = "#ffffff"),
    axis.title.x = element_blank(),
    axis.line.x = element_blank(),
    axis.ticks.x = element_blank())
theme_density_x = theme(
    axis.text.y = element_text(colour = "#ffffff"),
    axis.title.y = element_blank(),
    axis.line.y = element_blank(),
    axis.ticks.y = element_blank())
```


# Dataset

The following dataset is from experiment 2 of "How Relevant are Incidental Power Poses for HCI?" [(Jansen & HornbÃ¦k, 2018)](https://doi.org/10.1145/3173574.3173588). Study participants were asked to either make an expansive posture or a constrictive posture before performing a task. The experiment investigated whether posture could potentially have an effect on risk taking behavior.

First, we load the data.

```{r load-dataset}
pose_df = readr::read_csv("data/poses_data.csv", show_col_types = FALSE) %>%
  mutate(condition) %>%
  group_by(participant)
```

The data has been aggregated for each participant: - `condition = expansive` indicates expansive posture, and `condition = constrictive` indicates constrictive posture - The dependent variable is `change` which indicates the percentage change in risk-taking behavior. Thus, it is a continuous variable.

For the purposes of this demo, we are only concerned with these two variables. We can ignore the other variables for now. 

# Intuition of Bayesian Statistics

The Bayesian t-test (BEST) assumes that the data in the two conditions arises from two separate t-distributions. In the following section, we will describe the process for one of the conditions in the experiment.

We will use the $Normal(\mu = 20, \sigma = 20)$ as the prior distribution.

First, we define some functions for manual calculation of the posterior normal distribution:

```{r}
sigma_post = function(sigma_prior, sigma, n = 1) {
  sqrt(1 / (1 / (sigma_prior^2) + n / (sigma^2)))
}
mu_post = function(mu_prior, sigma_prior, mu, sigma, n = 1) {
  tau = sigma_post(sigma_prior, sigma, n)
  (tau^2 / sigma_prior^2)*mu_prior + (n * tau^2 / sigma^2)*mu
}
```

```{r}
d.p2 = tibble(
  group = c("prior", "expansive", "constrictive", "posterior"), 
  mu = c(20, 32.82, 31.61, mu_post(20, 20, 32.82, 7.52)), 
  sd = c(20, 7.52, 7.06, sigma_post(20, 7.52))
) %>%
  mutate(
    cutoff_group = list(c(1:7)),
    cutoff = list(c(0, 15, 25, 30, 32.82, 40, 100))
  ) %>%
  unnest(c(cutoff_group, cutoff)) %>%
  mutate(
    cutoff = if_else(group == 'prior', 100, cutoff),
    x = map(cutoff, ~ seq(from = -40, ., by = 0.1)),
    y = pmap(list(x, mu, sd), ~ dnorm(..1, ..2, ..3))
  )
```

In the plot below, we show the raw data distribution for the two conditions:

```{r, fig.height = 4, fig.width = 8}
p1 = pose_df %>%
  ggplot() +
  geom_point(aes(x = change, y = condition, colour = condition), 
             position = position_jitter(height = 0.1), alpha = 0.7) +
  scale_color_theme() + 
  labs(y = "Condition") +
  theme(
    legend.position = "none", 
    axis.line.y = element_blank(), 
    axis.ticks.y = element_blank(),
    axis.title.y = element_blank()
  ) +
  scale_x_continuous(limits = c(-150, 250), breaks = seq(-150, 250, by = 50))

p2.blank = tibble(y = c("expansive", "constrictive"), x = 0) %>%
  ggplot(aes(x, y)) +
  scale_color_theme() + 
  theme_density

cowplot::plot_grid(p2.blank, p1, nrow = 2)
```

First, we define a function to help us plot different cutoff groups.

```{r plot-preliminaries}
plot_preliminary <- function(data, group_num, group_name){
  data %>%
  filter(cutoff_group == group_num & group %in% group_name) %>%
  unnest(c(x, y)) %>%
  ggplot(aes(x, y)) +
  #geom_line(aes(color = group), size = 1) +
  # density
  geom_area(aes(fill = group, color = group), position = "identity", linewidth = 1, alpha = 0.3) +
  scale_x_continuous(limits = c(-40, 100)) +
  scale_y_continuous(limits = c(0, 0.1)) +
  scale_color_theme() +
  theme_density
}
```

```{r, fig.height = 4, fig.width = 8}
cowplot::plot_grid(
  plot_preliminary(d.p2, 0, NULL), 
  p1, nrow = 2)
```

Next, we plot the prior density:

```{r, fig.height = 4, fig.width = 8}
cowplot::plot_grid(
  plot_preliminary(d.p2, 1, 'prior'), 
  p1, nrow = 2)
```

Then we describe step by step, how the likelihood is computed:

```{r, fig.height = 4, fig.width = 8}
cowplot::plot_grid(
  plot_preliminary(d.p2, 1, 'expansive'), 
  p1, nrow = 2)
```

```{r, fig.height = 4, fig.width = 8}
cowplot::plot_grid(
  plot_preliminary(d.p2, 2, 'expansive'), 
  p1, nrow = 2)
```

```{r, fig.height = 4, fig.width = 8}
cowplot::plot_grid(
  plot_preliminary(d.p2, 3, 'expansive'), 
  p1, nrow = 2)
```

```{r, fig.height = 4, fig.width = 8}
cowplot::plot_grid(
  plot_preliminary(d.p2, 5, 'expansive'), 
  p1, nrow = 2)
```

```{r, fig.height = 4, fig.width = 8}
cowplot::plot_grid(
  plot_preliminary(d.p2, 6, 'expansive'), 
  p1, nrow = 2)
```

```{r, fig.height = 4, fig.width = 8}
cowplot::plot_grid(
  plot_preliminary(d.p2, 7, 'expansive'), 
  p1, nrow = 2)
```



We want to compute the posterior, which is the product of the prior and likelihood:

```{r, fig.height = 4, fig.width = 8}
cowplot::plot_grid(
  plot_preliminary(d.p2, 7, c('prior', 'expansive', 'posterior')), 
  p1, nrow = 2)
```


Of course, if you have `gganimate` and `magick` working on your computer, you can try the following code to get a gif! Here, we are not going to show the code.

```{r fig.height = 4, fig.width = 8, message=FALSE, warning=FALSE, echo=FALSE, eval=FALSE}
if(require("gganimate") & require("magick")){
  
  library(gganimate)
  library(magick)
  
  # create the top animation of distribution
  ani <-  d.p2 %>%
    filter(group != 'constrictive') %>% 
    # force frame index
    mutate(frame = if_else(
     group == 'expansive' | group == 'prior', as.integer(cutoff_group),
     as.integer(case_when(
       # only show posterior as the last frame
       group == 'posterior' ~ 8,
       TRUE ~ 0
     ))
    )) %>% 
    # force the last frame to have prior and expansive
    rbind(
       d.p2 %>% filter((group == 'expansive' | group == 'prior') & cutoff_group == 7) %>% 
         mutate(frame = 8)
    ) %>% 
    unnest(c(x, y)) %>%
    ggplot(aes(x, y)) +
    # plot them
    geom_area(aes(fill = group, color = group),  position = "identity", size = 1, alpha = 0.3) +
    scale_x_continuous(limits = c(-40, 100)) +
    scale_y_continuous(limits = c(0, 0.1)) +
    scale_color_theme() +
    theme_density +
    transition_manual(frame)
  
  # render the gif
  ani_gif <- animate(ani, width = 800, height = 200)
  
  a_mgif <- image_read(ani_gif)
  
  # create the bottom part
  set.seed(1)
  bottom_ani <- pose_df %>%
    # some hack to force gganimate to create a gif
    mutate(frame = 1) %>%
  ggplot() +
  geom_point(aes(x = change, y = condition, colour = condition), 
             position = position_jitter(height = 0.1, seed = 1234), 
             alpha = 0.7, size = 2) +
  scale_color_theme() + 
  labs(y = "Condition") +
  theme(
    legend.position = "none", 
    axis.line.y = element_blank(), 
    axis.ticks.y = element_blank(),
    axis.title.y = element_blank()
  ) +
  scale_x_continuous(limits = c(-40, 100), breaks = seq(-40, 100, by = 20)) +
  transition_manual(frame)
  bottom_gif <- animate(bottom_ani, width = 800, height = 200)
  
  b_mgif <- image_read(bottom_gif)
  
  # combine them in each frame
  new_gif <- image_append(c(a_mgif[1], b_mgif[1]), stack = TRUE)
  for(i in 2:8){
    combined <- image_append(c(a_mgif[i], b_mgif[1]), stack = TRUE)
    new_gif <- c(new_gif, combined)
  }
  
  new_gif
}
```



Fumeng: the content below needs better documentation....



# Model 1: Equal standard deviations

## Understanding the data

We plot the data distribution, the empirical density curve (blue line), and the theoretical density curve (black line).

```{r}
pose_df %>%
  mutate(c = as.factor(condition)) %>%
  ggplot(aes(x = change)) +
  # data distribution
  geom_histogram(
    aes(y = ..density..),
    binwidth = 10,
    fill = theme_yellow,
    alpha = .75,
    color = 'white'
  ) +
  # empirical density curve
  geom_density(size = 1,
               adjust = 1.5,
               color = theme_blue) +
  #  theoretical density curve, a t distribition with mean = 16, sd = 19, and nu = 6
   geom_function(
    color = "#222222",
    linetype = 'dashed',
    fun = function(x)
      dstudent_t(x, mu = 16,  sigma = 39, df = 6),
    size = 1
  ) + 
  scale_x_continuous(limits = c(-200, 200)) +
  theme(
    axis.line.y = element_blank(),
    axis.text.y = element_blank(),
    axis.ticks.y = element_blank(),
    axis.title.y = element_blank()
  )
```


## Step 1: model specification

Here we use a mathematical expression for the model above. 

$$
\begin{align}
y_{i} &\sim \mathrm{Student\_t}(\mu, \sigma_{0}, \nu_{0}) \\
\mu &= \beta_{0} + \beta_{1} * x_i \\
\sigma_{0}  &\sim \mathrm{HalfNormal}(0, 10) \\
\beta_{0} &\sim \mathrm{?} \\
\beta_{1} &\sim \mathrm{Normal}(0,2) \\
\nu_{0} &\sim \mathrm{?} \\
i & \in \{\mathrm{expansive}, \mathrm{constrictive}\}
\end{align}
$$

We translate this thought into `brms` formula using the function `bf`.

```{r}
model.1.formula <- bf(
                      # we think change is affected by different conditions.
                      change ~ condition,
                      # to tell brms which response distribution to use
                      family = student()
                    )
```

Now we can use `get_prior()` to inspect the available priors and formula. As what we learned, we have priors for 

```{r}
tibble(get_prior(model.1.formula, pose_df))
```


### prior checks

We look at the default priors from brms.

```{r fig.height=4, fig.width=15}
cowplot::plot_grid(
tibble(x = qstudent_t(ppoints(n = 500), df = 3, mu = 22.6, sigma = 38.8)) %>% 
  ggplot() +
  geom_density(aes(x = x), fill = theme_yellow, color = NA) +
  ggtitle('student_t(3, 22.6, 38.8) for Intercept') +
  coord_cartesian(xlim = c(-300, 300),expand = c(0)),
tibble(x = qgamma(ppoints(n = 500), shape = 2, rate = .1)) %>% 
  ggplot() +
  geom_density(aes(x = x), fill = theme_yellow, color = NA) +
  ggtitle('Gamma(2, 0.1) for nu') +
  coord_cartesian(xlim = c(1, 100), expand = 0),
tibble(x = qstudent_t(ppoints(n = 500), df = 3, mu = 0, sigma = 38.8)) %>% 
  ggplot() +
  geom_density(aes(x = x), fill = theme_yellow, color = NA) +
  ggtitle('student_t(3, 0, 38.8) for sigma') +
  coord_cartesian(xlim = c(0, 400),expand = c(0)),
ncol = 3)

```

We do a prior check for default priors to see the range of prior predictions.

```{r}
model.1.checks_default <- brm(
  model.1.formula,
  data = pose_df, 
  family = student_t(),
  prior = c(
    # need some priors for brms
    prior(normal(0, 3), class = 'b')
  ),
  # to allow draw from prior distributions
  sample_prior = 'only',
  backend = BRM_BACKEND,
  # save the model
  file = 'rds/model.1.checks_default.rds',
  file_refit = 'on_change' 
)
```

We draw from prior distributions using `predicted_draws`. 

```{r}
model.1.defaultpriorsamples <- 
  model.1.checks_default %>% 
    predicted_draws(tibble(condition = c('expansive', 'constrictive')))
```


Take a look at the prior prediction draws. You can ignore `.row`,`.chain`, '.iteration'. The `.draw` is the ID for each draw. `.prediction` is the value we care about.

```{r}
head(model.1.defaultpriorsamples)
```

We plot out the prediction draws. They look reasonable but have a wide range. We would expect so given the ranges of the priors.   

```{r  fig.height=2.5}
model.1.defaultpriorsamples %>% 
  ggplot(aes(x = .prediction, group = condition)) +
  geom_density(alpha = .5, color = NA, adjust = 2, fill = theme_yellow) +
  theme_density_x + 
  ggtitle('Checks default priors of model.1')
```

We want to use narrow priors. 

```{r fig.height=3, fig.width=10}
cowplot::plot_grid(
tibble(x = qstudent_t(ppoints(n = 1000), mu = 22.6, sigma = 10, df = 3)) %>% 
  ggplot() +
  geom_density(aes(x = x), fill = theme_yellow, color = NA) +
  ggtitle('t(3, 22.6, 10) for Intercept') +
  coord_cartesian(xlim = c(-30, 80), expand = 0),
tibble(x = qnorm(ppoints(n = 1000), mean = 0, sd = 2)) %>% 
  ggplot() +
  geom_density(aes(x = x), fill = theme_yellow, color = NA) +
  ggtitle('Normal(0, 2) for b') +
  coord_cartesian(xlim = c(-8, 8), expand = 0),
tibble(x = qnorm(ppoints(n = 1000), mean = 0, sd = 10)) %>% 
  ggplot() +
  geom_density(aes(x = x), fill = theme_yellow, color = NA) +
  ggtitle('HalfNormal(0, 10) for sigma') +
  coord_cartesian(xlim = c(0, 50), expand = c(0)),
ncol = 3)
```


We can do another prior check.

```{r}
model.1.checks <- brm(
  model.1.formula,
  data = pose_df, 
  family = student_t(),
  prior = c(
    prior(student_t(3, 22.6, 10), class = "Intercept"),
    prior(normal(0, 2), class = 'b'),
    prior(normal(0, 10), class = 'sigma', lb = 0)
  ),
  sample_prior = 'only',
  backend = BRM_BACKEND,
  file = 'rds/model.1.checks.rds',
  file_refit = 'on_change' 
)
```

We draw from the new prior distribution.

```{r}
model.1.priorsamples <- 
  model.1.checks %>% 
    predicted_draws(tibble(condition = c('expansive', 'constrictive')))
```


We compare two sets of prior distributions. Visually, using our priors have a narrower range. 

```{r  fig.height=5}
cowplot::plot_grid(
  
model.1.defaultpriorsamples %>% 
  ggplot(aes(x = .prediction, group = condition)) +
  geom_density(alpha = .5, color = NA, adjust = 2, fill = theme_yellow) +
  theme_density_x + 
  # coord_cartesian(xlim = c(-800, 1000)) +
  ggtitle('Checks for default priors of model.1')
,
model.1.priorsamples %>% 
  ggplot(aes(x = .prediction, group = condition)) +
  geom_density(alpha = .5, color = NA, adjust = 2, fill = theme_yellow) +
  theme_density_x + 
  # coord_cartesian(xlim = c(-800, 1000)) +
  ggtitle('Checks for our priors of model.1')
,
ncol = 1)
```


## Step 2: model fitting

Now we can fit the model. This model takes a

```{r}
model.1 <- brm(
  model.1.formula,
  data = pose_df, 
  family = student_t(),
  prior = c(
    prior(normal(0, 2), class = 'b'),
    prior(normal(0, 10), class = 'sigma', lb = 0)
  ),
  backend = BRM_BACKEND,
  file = 'rds/model.1.rds'
)
```

## Step 3: check posteriors

### aspect 1: mcmc traces

First, we check the MCMC traces to ensure that the chains are mixed well.

```{r}
color_scheme_set("teal")
mcmc_trace(model.1, facet_args = list(ncol = 4))
```
```{r}
plot(model.1)
```


### aspect 2: model metrics

We also check Rhat and ESS. We want Rhat to be close to 1 to ensure model convergence. We want Bulk ESS (effective sample size) to be at least a few hundreds (ideally, this should be at least a thousand.) to ensure reliable estimate of mean. We also want Tail ESS to be at this level. If ESSs are too low, it means there are too many correlations in posteriors draws. You need to increase the number of iterations and perhaps the number of chains. 

```{r}
summary(model.1)
```

### aspect 3: visually

Fumeng: I think this is bascially predictive checks below?

```{r}
pose_df.bayesiant.y <- pose_df$change

pose_df.bayesiant.yrep <- posterior_predict(model.1, ndraws = 30, seed = 1234)

ppc_dens_overlay(pose_df.bayesiant.y, pose_df.bayesiant.yrep)
```

Now we check the posterior prediction of this model to ensure that it generates reasonable predictions. 

```{r}
model.1.predictions <- 
  model.1 %>% 
    predicted_draws(tibble(condition = c('expansive', 'constrictive')))
```


```{r}
head(model.1.predictions)
```

```{r}
plot_predictions <- function(model, df = NULL, title = ''){
  
  if(is.null(df))
      df = tibble(condition = c('expansive', 'constrictive'), 
                           participant = c(-1, -1))
  model %>% 
    predicted_draws(df,
                    seed = 1234,
                    ndraws = NULL,
                    allow_new_levels = TRUE,
                    sample_new_levels = 'uncertainty') %>% 
    ggplot(aes(x = .prediction, colour = condition), fill = NA) +
    geom_density(alpha = .5, size = 1, adjust = 2) +
    scale_color_theme() +
    theme_density_x + 
    scale_y_continuous(breaks = 0, labels = 'constrictive') + 
    scale_x_continuous(breaks = seq(-150, 250, by = 50)) +
    coord_cartesian(xlim = c(-150, 250)) + 
    ggtitle(paste0('Posterior predictions of ', deparse(substitute(model))))
}
```


```{r}
cowplot::plot_grid(plot_predictions(model.1), 
                   p1 + 
                    scale_x_continuous(breaks = seq(-150, 250, by = 100)) +
                    coord_cartesian(xlim = c(-150, 250)), 
                   nrow = 2)
```

We now generate the posterior predictions of means, which are of interests here. 

```{r}
model.1.posteriors <- 
  model.1 %>% 
    epred_draws(tibble(condition = c('expansive', 'constrictive')))
```


Fumeng: I would save this
<!--
```{r fig.height = 2, fig.width = 9}
model.1.posteriors %>%
  ungroup() %>%
  # compare the 
  compare_levels(variable = .epred, by = condition) %>%
  median_qi(.width = .95) %>%
  ggplot() + 
  geom_pointinterval(aes(x = .epred, y = condition, xmin = .lower, xmax = .upper)) +
  geom_vline(xintercept = 0, linetype = 2, color = "#979797") +
  coord_cartesian(xlim = c(-5, 5)) +
  xlab("Difference in Mean") +
  theme(
    axis.text.x = element_text(size = 14),
    axis.text.y = element_text(size = 14),
    axis.title.x = element_text(size = 16),
    axis.title.y = element_blank()
  )
```
-->



```{r}
plot_posteriors <- function(model, df = NULL, title = ''){
  
  if(is.null(df))
     df = tibble(condition = c('expansive', 'constrictive'))
  
  model %>% 
    epred_draws(df, 
                # ignoring random effects if there is any
                #seed = 1234,
                ndraws = NULL,
                re_formula = NA) %>% 
    ggplot(aes(x = .epred, fill = condition)) +
    geom_density(alpha = .5, size = 1, adjust = 2, color = NA) +
    scale_color_theme() +
    theme_density_x + 
    scale_y_continuous(breaks = 0, labels = 'constrictive') + 
    scale_x_continuous(limits = c(-150, 250), breaks = seq(-150, 250, by = 50)) +
    ggtitle(paste0('Posterior means of ', deparse(substitute(model))))
}

cowplot::plot_grid(plot_posteriors(model.1), p1, nrow = 2)
```


# Model 2: the BEST test model

## Step 1: model specification

This model is the BEST test model as described by Kruschke in the paper *Bayesian estimation supersedes the t-test*. In this model, $\beta$ indicates the mean difference in the outcome variable between the two groups (in this case, the percent change in the BART scores). We fit different priors on $\beta$ and set different weights on these priors to obtain our posterior estimate.

$$
\begin{align}
y_{i} &\sim \mathrm{T}(\nu, \mu, \sigma) \\
\mu &= \beta_{0} + \beta_{1} * x_i \\
\sigma &= \sigma_{a} + \sigma_{b}*x_i \\
\beta_{1} &\sim \mathrm{Normal}(\mu_{0}, \sigma_{0}) \\
\sigma_a, \sigma_b &\sim \mathrm{Cauchy}(0, 2) \\
\nu &\sim \mathrm{exp}(1/30)\\
i & \in \{\mathrm{expansive}, \mathrm{constrictive}\}
\end{align}
$$



```{r}
model.2.formula <- bf(# we think change is affected by different conditions.
                      change ~ condition,
                      sigma ~ condition,
                      # to tell brms which response distribution to use
                      family = student())
```

```{r}
tibble(get_prior(model.2.formula, pose_df))
```

### prior check

Fumeng: not sure qcauchy has the correct paramaterization

```{r fig.height=4, fig.width=15}
cowplot::plot_grid(
  tibble(x = qnorm(ppoints(n = 1000),  mean = 0, sd = 2)) %>% 
  ggplot() +
  geom_density(aes(x = x), fill = theme_yellow, color = NA) +
  ggtitle('Normal(0 ,2) for Intercept') +
  coord_cartesian(expand = c(0)),
tibble(x = qexp(ppoints(n = 1000), rate = 0.0333)) %>% 
  ggplot() +
  geom_density(aes(x = x), fill = theme_yellow, color = NA) +
  ggtitle('exponential(0.0333) for nu') +
  coord_cartesian(expand = 0),
tibble(x = qcauchy(ppoints(n = 1000), location = 0, scale = 2)) %>% 
  ggplot() +
  geom_density(aes(x = x), fill = theme_yellow, color = NA) +
  ggtitle('cauchy(0, 2) for sigma') +
  coord_cartesian(expand = c(0)),
ncol = 3)

```


```{r}
model.2.priorchecks <- brm(
  model.2.formula,
  data = pose_df, 
  family = student_t(),
  prior = c(
    prior(normal(0, 2), class = 'b'),
    prior(cauchy(0, 2), class = 'b', dpar = 'sigma'),
    prior(exponential(0.0333), class = 'nu')
  ),
  sample_prior = 'only',
  backend = BRM_BACKEND,
  file = 'rds/model.2.priorchecks.rds',
  file_refit = 'on_change' 
)
```


```{r fig.height=2.5}
model.2.priorchecks %>% 
 epred_draws(tibble(condition = c('expansive', 'constrictive'))) %>% 
  ggplot(aes(x = .epred, group = condition)) +
  geom_density(alpha = .5, color = NA, adjust = 2, fill = theme_yellow) +
  theme_density_x + 
  ggtitle('Checks priors of model.2')
```

## Step 2:  model fiting

```{r}
model.2 <- brm(
  model.2.formula,
  data = pose_df, 
  family = student_t(),
  prior = c(
    prior(normal(0, 2), class = 'b'),
    prior(cauchy(0, 2), class = 'b', dpar = 'sigma'),
    prior(exponential(0.0333), class = 'nu')
  ),
  backend = BRM_BACKEND,
  file = 'rds/model.2.rds',
  file_refit = 'on_change' 
)
```



## Step 3: posterior checks


```{r}
summary(model.2)
```

```{r}
wrap_plots(plot_predictions(model.2) + scale_x_continuous(limits = c(-200,250), expand = c(0,0), breaks = seq(-150, 250, by = 50)) 
                   , 
                   p1 + scale_x_continuous(limits = c(-200,250), expand = c(0,0), breaks = seq(-150, 250, by = 50)) , 
                   nrow = 2)
```

```{r fig.height=5}
# draws.model.3 = 
wrap_plots(
  plot_posteriors(model.2), 
  p1,
nrow = 2)
```


```{r}
model.2.posteriors <- model.2 %>% 
                epred_draws(tibble(condition = c('expansive', 'constrictive')), 
                #seed = 1234,
                ndraws = NULL,
                re_formula = NA) 
```

# Model 3: the BEST model with better intercepts

## Step 1: model specification

$$
\begin{align}
y_{i} &\sim \mathrm{T}(\nu, \mu, \sigma) \\
\mu &= \beta_{i,j} + \beta_{1} * x_i \\
\sigma &= \sigma_{a} + \sigma_{b}*x_i \\
\beta_{1} &\sim \mathrm{Normal}(0, 2) \\
\sigma_a, \sigma_b &\sim \mathrm{HalfNormal}(0, 10) \\
\nu &\sim \mathrm{exp}(1/30)\\
i & \in \{\mathrm{expansive}, \mathrm{constrictive}\}\\
j & \in \{1, ..., \mathrm{N}\}
\end{align}
$$

```{r}
model.3.formula <- bf(# we think change is affected by different conditions.
                      change ~ condition + (1|participant),
                      sigma ~ condition,
                      # to tell brms which response distribution to use
                      family = student())
```

```{r}
tibble(get_prior(model.3.formula, pose_df))
```

## Step 2:  model fiting

```{r}
model.3 <- brm(
  model.3.formula,
  data = pose_df, 
  family = student_t(),
  prior = c(
    prior(normal(0, 2), class = 'b'),
    prior(normal(0, 2), class = 'b', dpar = 'sigma'),
    prior(normal(0, 2), class = 'sd', group = 'participant', lb = 0),
    prior(exponential(0.0333), class = 'nu')
  ),
  #backend = BRM_BACKEND,
  file = 'rds/model.3.rds',
  file_refit = 'on_change' 
)
```


## Step 3: posterior checks

```{r}
summary(model.3)
```


```{r}
cowplot::plot_grid(plot_predictions(model.3), p1, nrow = 2)
```



```{r}
cowplot::plot_grid(plot_posteriors(model.3), p1, nrow = 2)
```


```{r}
model.3.posteriors <-
  model.3 %>% 
  epred_draws(tibble(condition = c('expansive', 'constrictive')),
               re_formula = NA)
```


```{r fig.height=7, fig.width=10}
wrap_plots(
model.3.posteriors %>%
  mutate(model = 'model 3') %>%
  rbind(
    model.2.posteriors %>% 
      mutate(model = 'model 2'))  %>% 
  rbind(
    model.1.posteriors %>% 
      mutate(model = 'model 1')) %>% 
ggplot() + 
  geom_density(aes(x = .epred, fill = condition), adjust = 1.5, color = NA, alpha = .5) +
  facet_grid(model ~ .) +
  scale_x_continuous(limits = c(-150, 250), breaks = seq(-150, 250, by = 50)) +
  scale_color_theme() +
  theme_density_x +
  ggtitle('Compare the means of all three models'),
p1, nrow = 2, heights = c(4,1.5))
```


# Model 4: Poisson / Negative-Binomial Regression model

## Understanding the data

```{r}
pose_raw_df = read.csv("data/posture_data-raw.csv") %>%
  mutate(participant = factor(participant)) %>%
  rename(trial = trial.number)

head(pose_raw_df)
```


```{r}
pose_raw_df %>%
  mutate(c = as.factor(condition)) %>%
  ggplot(aes(x = pumps)) +
  geom_histogram(
    aes(y = ..density..),
    binwidth = 10,
    fill = theme_yellow,
    alpha = .5,
    color = 'white'
  ) +
  geom_density(size = 1,
               adjust = 1.5,
               color = theme_blue) +
   geom_function(
    color = "#222222",
    linetype = 'dashed',
    fun = function(x) # need to fix
      dpois(x, lambda = 37), # this does not use the log-link but brm does so the prior below is # log(387)
    size = 1
  ) + 
  theme(
    axis.line.y = element_blank(),
    axis.text.y = element_blank(),
    axis.ticks.y = element_blank(),
    axis.title.y = element_blank()
  )
```

## Step 1: model specification

$$
\begin{align}
y_{i} &\sim \mathrm{Poisson}(\lambda) \\
log(\lambda) &= \beta_{i,j} + \beta_{1} * x_i \\
\beta_{1} &\sim \mathrm{Normal}(0, 1) \\
i & \in \{\mathrm{expansive}, \mathrm{constrictive}\}\\
j & \in \{1, ..., \mathrm{N}\}
\end{align}
$$


## Step 2: prior predictive checks

```{r}
model.4.prior_pred = brm(pumps ~ 1 + condition + (1 | participant),
                      data = pose_raw_df, family = poisson,
                      prior = c(prior(normal(3.6, 0.5), class = Intercept),
                                prior(normal(0, 0.5), class = b)
                      ),  # this is the brms default
                      backend = BRM_BACKEND,
                      sample_prior = "only",
                      iter = 4000, warmup = 1000, cores = 4, chains = 4)
```


```{r}
model.4.prior_pred.samples <- model.4.prior_pred %>% 
    predicted_draws(tibble(condition = c('expansive', 'constrictive')), re_formula = NA)

head(model.4.prior_pred.samples)
```


```{r }
  ggplot() +
  geom_histogram(
    data = pose_raw_df,
    mapping = aes(x = pumps, y = ..density..),
    binwidth = 1,
    alpha = 1,
    fill = theme_yellow,
    color = 'white'
  ) +
  geom_density(model.4.prior_pred.samples,
               mapping = aes(x = .prediction, y = ..density..), adjust = 2, stroke = theme_blue) +
   geom_function(
    color = "#222222",
    linetype = 'dashed',
    fun = function(x)
        dpois(round(x), lambda = 35),
    size = 1
 ) +
  theme_density_x + 
 coord_cartesian(xlim = c(0, 100))
```

## Step 3: model fitting

```{r}
model.4 = brm(pumps ~ 1 + condition + (1 | participant),
                      data = pose_raw_df, family = poisson,
                      prior = c(prior(normal(3.6, 0.5), class = Intercept),
                                prior(normal(0, 0.5), class = b)
                      ),  # this is the brms default
                      backend = BRM_BACKEND,
                      file = 'rds/model.4.rds',
                      file_refit = 'on_change' ,
                      iter = 4000, warmup = 1000, cores = 4, chains = 4)
```


```{r}
summary(model.4)
```

```{r}
pose_raw_df.bayesian_poisson.y <- pose_raw_df$pumps

pose_raw_df.bayesian_poisson.yrep <- posterior_predict(model.4, ndraws = 30, seed = 1234)

ppc_dens_overlay(y = pose_raw_df.bayesian_poisson.y,
                 yrep = pose_raw_df.bayesian_poisson.yrep)
```


## Step 4: model interpretation
The results of this model are on the log-odds scale. What do the coefficients mean? The simplest way is to simply transform the data into a more interpretable scale and visualise the results:

```{r fig.height=5}
p.model.4 = pose_raw_df %>%
  ggplot() +
  geom_point(aes(x = pumps, y = condition, colour = condition), 
             position = position_jitter(height = 0.1), alpha = 0.7) +
  scale_color_theme() + 
  labs(y = "Condition") +
  theme(
    legend.position = "none", 
    axis.line.y = element_blank(), 
    axis.ticks.y = element_blank(),
    axis.title.y = element_blank()
  ) +
  scale_x_continuous(limits = c(0, 130), breaks = seq(0, 150, by = 30))

draws.model.4 = plot_predictions(model.4, df = crossing(condition = c('expansive', 'constrictive'), 
                                          trial = 0:29,
                                          participant = 0)) + 
    scale_x_continuous(breaks = seq(0, 150, by = 30)) +
    coord_cartesian(xlim = c(0, 150))

wrap_plots(
  draws.model.4, 
  p.model.4,
nrow = 2)
```


We generate the average of 30 trials using an average participant.

```{r}
model.4.posteriors <-  model.4 %>% 
    epred_draws(crossing(condition = c('expansive', 'constrictive'),     
                       trial = 0:29),
                re_formula = NA,
                allow_new_levels  = FALSE) %>% 
  mutate(model = 'model 4')  %>% 
  group_by(.draw, condition) %>% 
  summarise(.epred = mean(.epred))
```

```{r, fig.height = 2, fig.width = 9}
model.4.posteriors %>%
  ungroup() %>%
  compare_levels(.epred, by = condition) %>%
  median_qi(.width = .95) %>%
  ggplot() + 
  geom_pointinterval(aes(x = .epred, y = condition, xmin = .lower, xmax = .upper)) +
  geom_vline(xintercept = 0, linetype = 2, color = "#979797") +
  scale_x_continuous(breaks = seq(-10, 10, by = 2)) +
  coord_cartesian(xlim = c(-10, 10)) +
  xlab("Difference in Mean") +
  theme(
    axis.text.x = element_text(size = 14),
    axis.text.y = element_text(size = 14),
    axis.title.x = element_text(size = 16),
    axis.title.y = element_blank()
  )
```


Plot out the posteriors for mean.

```{r fig.height=7}
wrap_plots(
  model.4.posteriors %>% 
 ggplot(aes(x = .epred, fill = condition)) +
    geom_density(alpha = .5, size = 1, color = NA) +
    scale_color_theme() +
    facet_wrap(condition ~ ., ncol = 1) + 
    theme_density_x + 
    scale_x_continuous(limits = c(-100, 250), breaks = seq(-100, 250, by = 50)) +
    ggtitle(paste0('Posterior means of ', deparse(substitute(model)))), 
  p1,
nrow = 2)
```

From this, we can see that there does not appear to be a difference between the two conditions.


# Reporting

Let's use model 4

## model 

We will need the ESSs and RHat from this print. Also, if you want to report the standard deviation of random intercepts or CIs for other paramaters. You can find them via `summary(..)`

```{r}
summary(model.4)
```

## Credible Intervals

We compute the credible intervals (CIs; Bayesian analogy to confidence intervals) for the two conditions. 

```{r}
model.4.posteriors.CI <- 
model.4.posteriors %>% 
  group_by(condition) %>% 
  median_qi(.epred, width = .95)
```


```{r}
model.4.posteriors.CI
```


```{r fig.height=5, fig.width=10}
model.4.posteriors %>% 
ggplot() +
  geom_density(aes(x = .epred, fill = condition), alpha = .5, color = NA) +
  geom_point(model.4.posteriors.CI, 
             mapping = aes(x = .epred, y = 0), size = 3) + 
  geom_errorbarh(model.4.posteriors.CI, 
                 mapping = aes(x = .epred, xmin = .epred.lower, xmax = .epred.upper, y = 0), height = 0, linewidth = 1.5) + 
  facet_wrap(condition ~ ., ncol = 1) + 
  scale_x_continuous(limits = c(0, 80)) + 
  scale_y_continuous(expand = c(.02,.02)) + 
  scale_color_theme() +
  theme_density_x 

```

## subtraction

```{r}
model.4.posteriors_diff <- 
model.4.posteriors %>% 
  ungroup() %>% 
  compare_levels(variable = .epred, by = condition) %>% 
  ungroup()
```

```{r}
head(model.4.posteriors_diff)
```


```{r}
model.4.posteriors_diff.CI <-
model.4.posteriors_diff %>% 
  median_qi(.epred)

model.4.posteriors_diff.CI
```


```{r fig.height=4, fig.width=10}
model.4.posteriors_diff %>% 
ggplot() +
  geom_density(aes(x = .epred), alpha = .5,  fill = 'skyblue', color = NA, adjust = 2) +
  geom_point(model.4.posteriors_diff.CI, 
             mapping = aes(x = .epred, y = 0), size = 3) + 
  geom_errorbarh(model.4.posteriors_diff.CI, 
                 mapping = aes(x = .epred, xmin = .lower, xmax = .upper, y = 0), height = 0, linewidth = 1.5) + 
  #scale_x_continuous(limits = c(-50, 50)) + 
  xlab('expansive - constrictive') +
  ggtitle('Mean difference in expansive and constrictive') + 
  geom_vline(xintercept = 0, linetype = 2) + 
  scale_y_continuous(expand = c(.02,.02)) + 
  scale_x_continuous(limits = c(-10, 10), breaks = seq(-10, 10, by = 5)) + 
  scale_color_theme() +
  theme_density_x 

```


# Session info

```{r}
sessionInfo()
```