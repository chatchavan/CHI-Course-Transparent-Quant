---
title: "Session 4 - Bayesian modeling (chi2023-course)"
date: "`r format(Sys.time(), '%d %B, %Y')`"
author: Fumeng Yang and Abhraneel Sarma
output: 
  html_document: 
    css: "CHI23course-style.css"
    toc_depth: 2
    toc: yes
    toc_float:
      collapsed: no
      smooth_scroll: no
    df_print: kable
---


```{r setup, include=FALSE}
rm(list = ls(all.names = TRUE))
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, fig.width = 10, fig.height = 6)
```

# Introduction

## Load necessary packages

```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(rlang)
library(distributional)
library(brms)
library(tidybayes)
library(cowplot)
BRM_BACKEND <- ifelse(require("cmdstanr"), 'cmdstanr', 'rstan')

theme_set(theme_ggdist())
```

## Load the data

In this exercise, you will use the dataset in the file `df_between.csv` which contains the results of a between-subejects experiment where 30 participants are placed in three different conditions `cond` (levels: `off`, `constant`, `adaptive`), and the measure was `wpm`. The researchers want to see if participants `wpm` varies based on the condition, `cond`

```{r}
df_between <- read_csv("df_between.csv")
head(df_between)
```

Next, let's plot the data to get a better understanding:

```{r}
ggplot(df_between) +
  stat_histinterval(aes(x = wpm, y = cond))
```


## Step 1: Identify which priors you will need to specify

First, use the `get_prior` function to check out the default priors. You will need to specify the model syntax for this research question.

```{r}
get_prior(
  # TODO: write down the model syntax ...
  ,  
  data = df_between
)
```

## Step 2: Set your priors

Change the priors on the population-level effect coefficient (`class - "b"`) and standard deviation parameter (`class = "sigma"`). Hint: `normal`, `student_t`. For reference, their parameters can be found on the [Stan reference page](https://mc-stan.org/docs/functions-reference/unbounded-continuous-distributions.html).

```{r}
priors_choice <-  c(
    prior(
          # TODO: plug-in your choice in the line below (before the comma)
          ,
          class = 'b'),
    prior(
          # TODO: plug-in your choice
          , 
          class = 'sigma', lb = 0)
  )
```

Run the code below to visualise the priors specified.

```{r}
get_prior_dist = function(priors) {
  as_tibble(priors) |>
    mutate(prior_dist = map(prior, ~ eval_tidy(parse_expr(paste0("dist_", .)))))
}

get_prior_dist(priors_choice) |> 
  ggplot() +
  stat_dist_halfeye(aes(y = class, xdist = prior_dist))
```


## Step 3: Prior predictive checks

Enter the model syntax and model family below, and run the code. This will sample from the prior predictive distribution, which we will visualise in the next code block.

```{r}
m_prior_check <- brm(
  # TODO: write down the model syntax on the line below (before the comma)
  ,
  data = df_between,
  family =  , # TODO: write down the likelihood function (before the comma) 
  prior = priors_choice,
  seed = 1234,
  sample_prior = 'only'
)
```


Fill in the aesthetics for ggplot to show the prior predictive distribution for each condition. To verify that your specified prior predictive distributions are appropriate, here are somethings to check:

1. The distribution should be positive-only, as the `wpm` variable cannot take negative-values
2. On average, the mean of the distributions should be around 50
4. The distributions should assign probability for values less than 100 (as values greater than 100 are quite unlikely)

To run the code below, you'll need to inspect the data frame `newdata_predicted`, identify the variables and enter them.


```{r}
newdata <- crossing(cond = df_between$cond)
newdata_predicted <- add_predicted_draws(newdata, m_prior_check)

newdata_predicted %>% 
ggplot(aes(
  x = , # TODO: enter the variable for predictions here (Don't forget a comma at the end.)
  y =  # TODO: enter the variable for conditions here.
)) +
stat_halfeye()
```

## Step 4: Running the model

In this step you will run the Bayesian model. Fill in the model syntax and family (from Step 2) here:

```{r}
m <- brm(
  # TODO: write out the model formula 
  wpm ~ cond,
  data = df_between,
  family =  student(), # TODO: write down the likelihood function, 
  prior = priors_choice,
  seed = 1234
)
```

## Step 4: Checking the model results and reporting them

```{r}
summary(m)
```

**Task:** Describe below how you would interpret and report these results



## Step 5: Posterior predictive checks

The code below implements a posterior predictive checks. In other words, it compares the posterior predictive distribution from your Bayesian model with the distribution of the data. We have provided the code which will extract posterior predictive draws from your model (stored in the data frame `posterior_predictive_draws`). 

To run the code below, you'll need to inspect the data frame `posterior_predictive_draws`, identify the variables and enter them to implement a posterior predictive check.

```{r}
posterior_predictive_draws = newdata %>%
  add_predicted_draws(m, ndraws = NULL, seed = 1234)

posterior_predictive_draws %>% 
  ggplot() +
  stat_halfeye(
    aes(
      x = , # TODO: enter the variable here. (Don't forget a comma.)
      y =   # TODO: enter the variable here
    ),
    position = position_nudge(y = .1),
    height = .8
  ) +
  geom_point(df_between,
             mapping = aes(
                x = , # TODO: plug in x, 
                y =   # TODO: plug in y (Note: the variable is a column from `df_between`
                      #      ---which is the first argument of `geom_point()`.)
             ),
             size = 5, shape = 20, alpha = .4) 
  
  
```

**Task:** Based on the posterior predictive distribution, describe below why or why not the model is a good fit for the data.

## Step 6: Making inferences using Posterior means

The code below extract posterior draws for the mean of each condition (stored in the data frame `posterior_draws`). Recall that your research question was to determine if the three conditions have an effect on the variable `wpm`.

To run the code below, you'll need to inspect the data frame `posterior_draws`, identify the variables and enter them to visualise the results.

```{r}
posterior_draws <- 
newdata %>%
  add_epred_draws(m, seed = 1234)  
  
posterior_draws %>% 
  ggplot() +
  stat_halfeye(
    aes(
      x = # TODO: enter the variable here, 
      y = # TODO: enter the variable here
    ),
    position = position_nudge(y = .1),
    height = .8
  ) +
  geom_point(df_between,
             mapping = aes(
                x = # TODO: plug in x, 
                y = # TODO: plug in y
             ),
             size = 5, shape = 20, alpha = .4)
```

Next, you will estimate the median point estimate and 95% posterior credible intervals for each condition using the `median_qi` function. 

The `median_qi` function calculates the median point estimate and upper and lower 95% quantile intervals based on your posterior draws (samples). However, as you want to calculate the point and interval estimates for each condition, you will need to `group_by` the condition

```{r}
posterior_draws %>% 
  group_by( 
      # TODO: plug in the variable, 
  ) %>% 
  median_qi(
      # TODO: plug in the variable
  )
```

The `compare_levels` function allows you to calculate the difference between the conditions. In a Bayesian model, we can simply take the difference between draws from two conditions. We have implemented the code for you---please take your time to inspect the resultant data frame

```{r}
posterior_draws_diff <- posterior_draws %>% 
  compare_levels(variable = .epred, 
                 by = cond, 
                 comparison = list(c('adaptive', 'constant'), 
                                   c('off', 'constant'), 
                                   c('adaptive', 'off')))
```


Next, you will estimate the median point estimate and 95% posterior credible intervals for the difference between the conditions using the `median_qi` function.

```{r}
posterior_draws_diff %>% 
  group_by( 
     # TODO: plug in the variable, 
  ) %>% 
  median_qi(
     # TODO: plug in the variable
  )
```

Finally, we can visualise the result i.e. the mean difference between each pair of conditions. Enter the `x` and `y` variables to visualise the posterior mean difference between each pair of conditions:

```{r}
posterior_draws_diff %>% 
  ggplot() + 
  stat_halfeye(aes(
    x =  # TODO: plug in x, 
    y =  # TODO: plug in y, 
    )) + 
  geom_vline(xintercept = 0, linetype = 2)
```



